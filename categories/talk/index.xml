<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>talk | Chalmers Security &amp; Privacy Lab</title><link>https://www.cse.chalmers.se/research/group/security/categories/talk/</link><atom:link href="https://www.cse.chalmers.se/research/group/security/categories/talk/index.xml" rel="self" type="application/rss+xml"/><description>talk</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 08 Oct 2021 00:00:00 +0000</lastBuildDate><image><url>https://www.cse.chalmers.se/research/group/security/media/icon_huf405b5a3d64669240eafa59ffeef17e8_561926_512x512_fill_lanczos_center_2.png</url><title>talk</title><link>https://www.cse.chalmers.se/research/group/security/categories/talk/</link></image><item><title>Practical Data Access Minimization in Trigger-Action Platforms</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-10-08-css-talk48/</link><pubDate>Fri, 08 Oct 2021 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-10-08-css-talk48/</guid><description/></item><item><title>When Good Components Go Bad: Formally Secure Compilation Despite Dynamic Compromise</title><link>https://www.cse.chalmers.se/research/group/security/event/2019/2019-12-05-css-talk27/</link><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2019/2019-12-05-css-talk27/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Catalin Hritcu from Inria Paris, France \&lt;br>
&lt;strong>When:&lt;/strong> 14:00 - 15:00 Thursday {{ page.date | date_to_long_string }}\&lt;br>
&lt;strong>Where:&lt;/strong> Room ES52, Linsen (Maskingränd 2).\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;/p>
&lt;p>We propose a new formal criterion for evaluating secure
compartmentalization schemes for unsafe languages like C and C++,
expressing end-to-end security guarantees for software components that
may become compromised after encountering undefined behavior&amp;mdash;for
example, by accessing an array out of bounds. Our criterion is the
first to model dynamic compromise in a system of mutually distrustful
components with clearly specified privileges. It articulates how each
component should be protected from all the others&amp;mdash;in particular,
from components that have encountered undefined behavior and become
compromised.
To illustrate the model, we construct a secure compilation chain for a
small unsafe language with buffers, procedures, and components,
targeting a simple abstract machine with built-in
compartmentalization. We propose a novel proof technique and give a
machine-checked proof in Coq that this compiler satisfies our secure
compilation criterion. Finally, we show that the protection guarantees
offered by the compartmentalized abstract machine can be achieved at
the machine-code level using either software fault isolation or a
tag-based reference monitor.&lt;/p>
&lt;p>&lt;strong>Speaker Bio:&lt;/strong>\&lt;/p>
&lt;p>&lt;a href="https://prosecco.gforge.inria.fr/personal/hritcu" target="_blank" rel="noopener">Catalin Hritcu&lt;/a> is a
researcher at Inria Paris where he works on security foundations. He is
particularly interested in formal methods for security (secure compilation,
compartmentalization, memory safety, security protocols, integrity, information
flow), programming languages (program verification, proof assistants, type
systems, semantics, formal metatheory, certified tools, property-based testing),
and the design and verification of security-critical systems (reference
monitors, secure compilation chains, secure hardware). He was awarded an ERC
Starting Grant on formally secure compilation
&lt;a href="https://secure-compilation.github.io" target="_blank" rel="noopener">(https://secure-compilation.github.io)&lt;/a>,
and is also actively involved in the design of the F* verification system
&lt;a href="https://www.fstar-lang.org/" target="_blank" rel="noopener">(https://www.fstar-lang.org/)&lt;/a>, which is used for
building a formally verified HTTPS stack
&lt;a href="https://project-everest.github.io" target="_blank" rel="noopener">(https://project-everest.github.io)&lt;/a>. Catalin
received a PhD from Saarland University in Saarbrücken, a Habilitation from ENS
Paris, and was previously also a Research Associate at University of
Pennsylvania and a Visiting Researcher at Microsoft Research Redmond.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Risk Analysis of Privacy Policies</title><link>https://www.cse.chalmers.se/research/group/security/event/2019/2019-11-22-css-talk26/</link><pubDate>Fri, 22 Nov 2019 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2019/2019-11-22-css-talk26/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Raúl Pardo Jimenez from IT University of Copenhagen, Denmark \&lt;br>
&lt;strong>When:&lt;/strong> 11:00 - 12:00 Friday {{ page.date | date_to_long_string }}\&lt;br>
&lt;strong>Where:&lt;/strong> Room 8103, EDIT building.\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;/p>
&lt;p>In this talk, I present an approach to enhance informed consent
for the processing of personal data. The approach relies on a
privacy policy language used to express, compare and analyze
privacy policies. I describe a tool that automatically reports
the privacy risks associated with a given privacy policy in order
to enhance data subjects' awareness and to allow them to make
more informed choices. The risk analysis of privacy policies is
illustrated with an IoT example.&lt;/p>
&lt;p>This talk is based on work published at
DBSec19, and a paper under submission to the Journal of Computer
Security. You can find an publicly available version of the paper here
&lt;a href="https://hal.inria.fr/hal-02067924v2">https://hal.inria.fr/hal-02067924v2&lt;/a>&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>The Simplest Multi-key Linearly Homomorphic Signature Scheme</title><link>https://www.cse.chalmers.se/research/group/security/event/2019/2019-10-17-css-talk25/</link><pubDate>Thu, 17 Oct 2019 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2019/2019-10-17-css-talk25/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Elena Pagnin from Aarhus University, Denmark \&lt;br>
&lt;strong>When:&lt;/strong> 10:00 - 11:00 Thursday {{ page.date | date_to_long_string }}\&lt;br>
&lt;strong>Where:&lt;/strong> Room 8103, EDIT building.\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
We consider the problem of outsourcing computation on data authenticated by different users.
Our aim is to describe and implement the simplest possible solution to provide data integrity in cloud-based scenarios.
Concretely, our multi-key linearly homomorphic signature scheme (mklhs) allows users to upload signed data on a server,
and at any later point in time any third party can query the server to compute a linear combination of data authenticated
by different users and check the correctness of the returned result. Our construction generalizes Boneh et al.’s linearly
homomorphic signature scheme (PKC’09 [7]) to the multi-key setting and relies on basic tools of pairing-based cryptography.
Compared to existing multi-key homomorphic signature schemes, our mklhs is a conceptually simple and elegant direct construction,
which trades-off privacy for efficiency. The simplicity of our approach leads us to a very efficient construction that enjoys
significantly shorter signatures and higher performance than previous proposals. Finally, we implement mklhs using two
different pairing-friendly curves at the 128-bit security level, a Barreto-Lynn-Scott curve and a Barreto-Naehrig curve.
Our benchmarks illustrate interesting performance trade-offs between these parameters, involving the cost of exponentiation and
hashing inpairing groups.
We provide a discussion on such trade-offs that can be useful to other implementers of pairing-based protocols.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>The Rush Dilemma: Attacking and Repairing Smart Contracts on Forking Blockchains</title><link>https://www.cse.chalmers.se/research/group/security/event/2019/2019-10-16-css-talk24/</link><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2019/2019-10-16-css-talk24/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Daniele Friolo from Sapienza University of Rome, Italy \&lt;br>
&lt;strong>When:&lt;/strong> 15:00 - 16:00 Wednesday {{ page.date | date_to_long_string }}\&lt;br>
&lt;strong>Where:&lt;/strong> Room 5128, EDIT building.\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;/p>
&lt;p>We investigate the security of smart contracts within a blockchain that can fork (as Bitcoin and Ethereum). In particular, we focus on multi-party computation (MPC) protocols run on-chain with the aid of smart contracts, and observe that honest players face the following dilemma: Should I rush sending protocol&amp;rsquo;s messages based on the current view of the blockchain, or rather wait that a message is confirmed on the chain before sending the next one?&lt;/p>
&lt;p>To the best of our knowledge, the (implicit) default option used in previous work is the second one and thus known on-chain MPC protocols take long time to be executed on those blockchains with a long confirmation time (e.g., 1 hour per transaction in Bitcoin). While the first option would clearly be preferable for efficiency, we show that this is not necessarily the case for security, as there are natural examples of on-chain MPC protocols that simply become insecure in presence of rushing players.&lt;/p>
&lt;p>Our contributions are twofold:&lt;/p>
&lt;ul>
&lt;li>For the concrete case of fairly tossing multiple coins with penalties, we show that the lottery protocol of Andrychowicz et al. (S&amp;amp;P &amp;lsquo;14) becomes insecure in the presence of rushing players. In addition, we present a new protocol that instead retains security even if the players are rushing.&lt;/li>
&lt;li>We design a compiler that takes any on-chain MPC protocol and transforms it into another one (for the same task) that remains secure even in the presence of rushing players. The only (unavoidable) requirement is that honest players start to be rushing after the first round of the protocol (by all players) has been confirmed on the blockchain.&lt;/li>
&lt;/ul>
&lt;p>Our techniques are inspired by ideas on resettably secure computation (Goyal and Sahai, EUROCRYPT &amp;lsquo;09). We also provide a prototype implementation of our coin tossing protocol using Ethereum smart contracts, and instantiate our generic compiler in a concrete setting, showing that both our constructions yield considerable improvements in terms of efficiency.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>SAID: Reshaping Signal into an Identity-Based Asynchronous Messaging Protocol with Authenticated Ratcheting</title><link>https://www.cse.chalmers.se/research/group/security/event/2019/2019-04-24-css-talk23/</link><pubDate>Wed, 24 Apr 2019 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2019/2019-04-24-css-talk23/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Elena Pagnin from Aarhus University, Denmark \&lt;br>
&lt;strong>When:&lt;/strong> 10:00 - 11:00 Wednesday {{ page.date | date_to_long_string }}\&lt;br>
&lt;strong>Where:&lt;/strong> Room Analysen, EDIT building.\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
As messaging applications are becoming increasingly popular, it is of utmost importance to analyze their security and mitigate existing weaknesses. This paper focuses on one of the most acclaimed messaging applications: Signal.&lt;/p>
&lt;p>Signal is a protocol that provides end-to-end channel security, forward secrecy, and post-compromise security. These features are achieved thanks to a key-ratcheting mechanism that updates the key material at every message. Due to its high security impact, Signal’s key-ratcheting has recently been formalized, along with an analysis of its security.&lt;/p>
&lt;p>In this paper, we revisit Signal, describing some attacks against the original design and proposing SAID: Signal Authenticated and IDentity-based. As the name indicates, our protocol relies on an identity-based setup, which allows us to dispense with Signal’s centralized server. We use the identity-based long-term secrets to obtain persistent and explicit authentication, such that SAID achieves higher security guarantees than Signal.&lt;/p>
&lt;p>We prove the security of SAID not only in the Authenticated Key Exchange (AKE) model (as done by previous work), but also in the Authenticated and Confidential Channel Establishment (ACCE) model, which we adapted and redefined for SAID and asynchronous messaging protocols in general into a model we call identity-based Multistage Asynchronous Messaging (iMAM). We believe our model to be more faithful in particular to the true security of Signal, whose use of the message keys prevents them from achieving the composable guarantee claimed by previous analysis.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Trusted Execution Environments for Privacy-preserving Cloud Applications</title><link>https://www.cse.chalmers.se/research/group/security/event/2018/2018-01-26-css-talk22/</link><pubDate>Fri, 26 Jan 2018 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2018/2018-01-26-css-talk22/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Pascal Felber from the University of Neuchâtel, Switzerland \&lt;br>
&lt;strong>When:&lt;/strong> 11:15 - 12:30 Friday{{ page.date | date_to_long_string }}\&lt;br>
&lt;strong>Where:&lt;/strong> EL42, EDIT building.\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
In this talk, we will give an overview of popular trusted execution environments (TEEs), with special emphasis on Intel&amp;rsquo;s SGX, and we will describe how they can be exploited for implementing privacy-preserving operations in the Cloud that are both secure and efficient. We will discuss their main benefits and limitations, and we will present some of the recent systems that have been developed on top of them.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>CLIO: Cryptographically Secure Information Flow Control on Key-Value Stores</title><link>https://www.cse.chalmers.se/research/group/security/event/2017/2017-05-05-css-talk21/</link><pubDate>Fri, 05 May 2017 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2017/2017-05-05-css-talk21/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Pablo Buiras, PhD from Chalmers, now PostDoc at Harvard university\&lt;br>
&lt;strong>When:&lt;/strong> 10:30 - 11:30 Friday{{ page.date | date_to_long_string }}\&lt;br>
&lt;strong>Where:&lt;/strong> room EDIT 3364\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
Cryptography can in principle be used to protect users' data when stored
or transmitted, but in practice is error-prone and can potentially
result in a violation of a user&amp;rsquo;s security concerns.
Information flow control (IFC) systems, on the other hand,
can automatically enforce security policies on data with
policy languages expressive enough to capture many desired
confidentiality and integrity requirements.
In this talk I will present CLIO, an Information flow control (IFC)
system that transparently incorporates cryptography
to enforce confidentiality and integrity policies on untrusted key-value storage.
CLIO insulates developers from explicitly manipulating keys and cryptographic
primitives by leveraging the policy language of the IFC system to
automatically use the appropriate keys and correct cryptographic operations.
Our system relies on a CPA-secure cryptosystem, and we show that CLIO is secure
with a novel proof technique composing cryptographic proof techniques with standard
programming language techniques.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Historical Analyses of the Client-Side Web Security and How to tell people they have an issue</title><link>https://www.cse.chalmers.se/research/group/security/event/2017/2017-04-06-css-talk20/</link><pubDate>Thu, 06 Apr 2017 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2017/2017-04-06-css-talk20/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> room EDIT 8103\&lt;br>
&lt;strong>When:&lt;/strong> 9:30-10:30{{ page.date | date_to_long_string }}\&lt;br>
&lt;strong>Where:&lt;/strong> room EDIT 8103 \&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
In this talk, I will present two lines of research I am
currently pursuing. On the one hand, my work focusses on client-side Web
security. To better understand how the eco system evolved, we conducted
a historical study of the last 20 years of the Web using data from the
Internet Archive. Given that the Archive stores all client-side code as
well as relevant header information, this enabled us to analyze trends
over the last years, which allow us to draw conclusions on how future
security mechanisms should be implemented.&lt;/p>
&lt;p>On the other hand, while as a community we have become very good at
discovering vulnerabilities at scale (regardless of Web or network level
flaws), informing the affected parties about the issues has only been
treated as a side note in previous research. To understand how such
notifications can be conducted at scale, we conducted an experiment in
which we notified more than 44,000 vulnerable domains, using different
communication channels. Our work shows that reaching administrators is
the biggest roadblock to a successful notification. In my talk, I will
also discuss some of the technical and human challenges we face when
notifying at scale, moreover highlighting which of these areas require
further research.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Recent work on probabilistic programming languages</title><link>https://www.cse.chalmers.se/research/group/security/event/2017/2017-03-06-css-talk19/</link><pubDate>Mon, 06 Mar 2017 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2017/2017-03-06-css-talk19/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Daniel Huang \&lt;br>
&lt;strong>When:&lt;/strong> 16.00 {{ page.date | date_to_long_string }}\&lt;br>
&lt;strong>Where:&lt;/strong> 5128 (Grouproom) \&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
In this talk, we will present some of our recent work on probabilistic programming languages. In the first half of the talk, we will describe a semantics for these languages based on Type-2 computable distributions. Such an approach enables us to reason denotationally about probabilistic programs as well as in terms of sampling. In the second half, we will describe a compiler for a simple probabilistic programming language. The compiler uses a sequence of intermediate languages to gradually and successively transform a specification of a probabilistic model into a Markov Chain Monte Carlo inference algorithm for execution on the CPU or GPU.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Privacy and security threat modeling: current research directions</title><link>https://www.cse.chalmers.se/research/group/security/event/2017/2017-02-08-css-talk18/</link><pubDate>Wed, 08 Feb 2017 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2017/2017-02-08-css-talk18/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Riccardo Scandariato \&lt;br>
&lt;strong>When:&lt;/strong> 11h00 - 11h30 {{ page.date | date_to_long_string }}\&lt;br>
&lt;strong>Where:&lt;/strong> Lindholmen, Jupiter building, 4th floor, room 473\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
Threat analysis is the cornerstone of security-by-design and privacy-by-design approaches for building more secure and privacy-friendly software systems. Threat analysis provides the means to assess a design model (e.g., a software architecture) and identify potential flaws early on in the software development life-cycle. This talk will overview the issues we (empirically) found in state-of-the-practice threat analysis techniques.
Moving forward, the talk will outline our present research directions in the field of threat analysis, with particular focus on a) improving the efficiency of said techniques and b) supporting automated analysis and refactoring.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Security and Privacy on Medical Devices</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-10-26-css-talk17/</link><pubDate>Wed, 26 Oct 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-10-26-css-talk17/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Pablo Picazo\&lt;br>
&lt;strong>When:&lt;/strong> Friday, {{ page.date | date_to_long_string }}\&lt;br>
&lt;strong>Where:&lt;/strong> room 5128\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
The new generation of Implantable Medical Devices (IMDs) is a reality but the security threats mainly linked to the inclusion of wireless connectivity seem to have not received the adequate attention. The security mechanisms supported on-board of these devices must guarantee a balance between the patient safety and the security of the device &amp;ndash; that is, a trade-off between the normal operation mode and the emergency mode. Once introduced the particularities and the security risks of these devices, different security solutions will be revised in the context of identification, key generation, random number generation, etc.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>ZKBoo: Faster Zero-Knowledge for Boolean Circuits</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-08-25-css-talk6/</link><pubDate>Thu, 25 Aug 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-08-25-css-talk6/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> &lt;a href="https://link.com/" target="_blank" rel="noopener">Fname Lname&lt;/a>\&lt;br>
&lt;strong>When:&lt;/strong> Thursday, {{ page.date | date_to_long_string }}, 14:00-15:00\&lt;br>
&lt;strong>Where:&lt;/strong> Room 3364\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
In this talk we describe ZKBoo, a proposal for practically efficient
zero-knowledge arguments especially tailored for Boolean circuits and
report on a proof-of-concept implementation. As an highlight, we can
generate (resp. verify) a non-interactive proof for the SHA-1 circuit in
approximately 13ms (resp. 5ms), with a proof size of 444KB. Our
techniques are based on the “MPC-in-the-head” approach to zero-knowledge
of Ishai et al. (IKOS), which has been successfully used to achieve
significant asymptotic improvements. Our contributions include: 1) A
thorough analysis of the different variants of IKOS, which highlights
their pro and cons for practically relevant soundness parameters; 2) A
generalization and simplification of their approach, which leads to
faster Sigma-protocols (that can be made non-interactive using the
Fiat-Shamir heuristic) for statements of the form “I know x such that y
= f(x)” (where f is a circuit and y a public value); 3) A case study,
where we provide explicit protocols, implementations and benchmarking of
zero-knowledge protocols for the SHA-1 and SHA-256 circuits;&lt;/p>
&lt;p>The paper was published at USENIX Security Symposium 2016 and received
best paper award.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Enhancing the COWL W3C Standard</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-06-08-css-talk16/</link><pubDate>Wed, 08 Jun 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-06-08-css-talk16/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Niklas Andreasson\&lt;br>
&lt;strong>When:&lt;/strong> 10:00, June 8 \&lt;br>
&lt;strong>Where:&lt;/strong> room EDIT 8103\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
Web applications are often composed by resources such as JavaScript
written, and provided, by different parties. This reuse leads to questions concerning security,
and whether one can trust that third-party code will not leak users’ sensitive information.
As it stands today, these concerns are well-founded.&lt;/p>
&lt;p>With the web’s current security primitives there is a trade-off between
developer flexibility and user privacy. If developers choose to include untrusted code then
users’ privacy suffers. On the other hand, if developers abstain from reusing third-party code,
user privacy is favoured, on the cost of developer flexibility. This trade-off can
partly be attributed to the fact that the security primitives are discretionary, where untrusted
code either is granted or denied access to data. After code has been granted access to data
there is no further attempt to verify that the data is used properly.&lt;/p>
&lt;p>In 2014, Stefan et al. proposed a security mechanism which called COWL
(Confinement of Origin Web Labels). COWL is a mandatory access control
which is able to let untrusted code compute on sensitive information, while confining
it. Through this, COWL is able to address some of the shortcomings of the web’s current
security mechanisms, and in the end effectively eliminate the trade-off that exists. Since
the introduction of COWL, it has gone on to become a W3C standard.&lt;/p>
&lt;p>This thesis evaluates the COWL W3C specification by deploying it in
Mozilla Firefox. While COWL aims to mainly address information leaks caused by bugs, we
bring the specification towards addressing malicious code by highlighting two
covert channels: one due to the browser layout engine, and another due to browser
optimizations. Furthermore, we implement two case studies which shows how COWL can be used, and as
part of this, note some practical problems.Through the thesis we managed to make
contributions to the COWL W3C specification.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Selene: Voting with Transparent Verification and Coercion Mitigation</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-06-08-css-talk15/</link><pubDate>Wed, 08 Jun 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-06-08-css-talk15/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Peter Y A Ryan (University of Luxembourg)\&lt;br>
&lt;strong>When:&lt;/strong> 14:30, June 8 \&lt;br>
&lt;strong>Where:&lt;/strong> room EDIT 81033\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
In conventional cryptographic E2E verification schemes, voters are
provided with encrypted ballots that enable them to confirm that their
vote is accurately included in the tally. Technically this is very
appealing, but voters, election officials etc. need to understand some
rather subtle arguments to appreciate the integrity and ballot
secrecy guarantees provided by such mechanisms.&lt;/p>
&lt;p>A simple way to achieve a degree of verifiability and ballot privacy is
to provide each voter with a unique, private tracking number. Votes are
posted on a bulletin board in the clear along with their tracking
number. Thus voters can visit the WBB confirm that there is an entry
with their tracking number showing the correct vote. The beauty of this
approach is its simplicity and understandability. There are, however,
two drawbacks: we must ensure that trackers are unique and a coercer can
demand that the voter reveal her tracking number. It is interesting to
note that the coercer must ask for the tracker before posting. If he
asks after posting the voter has a simple strategy to fool him: just
reads off a tracker number with the coercer&amp;rsquo;s required vote from the WBB.&lt;/p>
&lt;p>In this talk, I describe a scheme that addresses both of these problems.
The main idea is to close off the coercer&amp;rsquo;s window of opportunity by
ensuring that the voters only learn their tracker numbers after votes
have been posted. Notification of the trackers must provide high
assurance but be deniable. The resulting scheme provides
receipt-freeness but also provides a more immediately understandable
form of verifiability: voters can find their vote, in the clear, in the
tally identified by their secret tracker.&lt;/p>
&lt;p>However, there is a sting in the tail: a coerced voter might light on
the coercer&amp;rsquo;s tracker, or the coercer may simply claim that the tracker
is his. I describe some elaborations of the basic scheme to counter this
problem.&lt;/p>
&lt;p>&lt;a href="http://eprint.iacr.org/2015/1105.pdf">http://eprint.iacr.org/2015/1105.pdf&lt;/a>&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Verification of differential private computationss</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-31-css-talk14/</link><pubDate>Tue, 31 May 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-31-css-talk14/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Gilles Barthe (IMDEA)\&lt;br>
&lt;strong>When:&lt;/strong> 13:30, May 31 \&lt;br>
&lt;strong>Where:&lt;/strong> room EDIT 8103\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
Differential privacy is a statistical notion of privacy which achieves
compelling trade-offs between input privacy and accuracy (of outputs).
Differential privacy is also an attractive target for verification:
despite their apparent simplicity, recently proposed algorithms have
intricate privacy and accuracy proofs. We present two program logics
for reasoning about privacy and accuracy properties of probabilistic
computations. The accuracy logic captures reasoning about the union
bound, a simple but effective tool from probablility theory, whereas
the privacy logic captures fine-grained reasoning about probabilistic
couplings, a powerful tool for studying Markov chains. We illustrate
the strengths of our program logics with novel and elegant proofs of
challenging examples from differential privacy.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title> Privacy engineering: from the building blocks to the system</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-29-css-talk11/</link><pubDate>Sun, 29 May 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-29-css-talk11/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Thibaud Antignac\&lt;br>
&lt;strong>When:&lt;/strong> 11:00 am, April 29\&lt;br>
&lt;strong>Where:&lt;/strong> EDIT 8103\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
This talk will be about privacy engineering, a field mainly concerned
with techniques, methods, and tools to systematically take into account
and address privacy issues when building a system. During this journey,
we will explore the difference between security and privacy and see why
the study of privacy in a system requires an interdisciplinary approach.
Finally, we will have a look at the current research challenges needed
to be tackled to be in a situation to deliver more privacy in
information systems.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Architectural requirements for language-level control of external timing channels</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-27-css-talk10/</link><pubDate>Fri, 27 May 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-27-css-talk10/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Aslan Askarov (Aarhus University)\&lt;br>
&lt;strong>When:&lt;/strong> 14:15, April 27\&lt;br>
&lt;strong>Where:&lt;/strong> room ED\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
A promising new approach to controlling timing channels relies on distinguishing between the direct timing dependencies that are visible at the program control flow level, and the indirect timing dependencies that typically have architectural nature. The approach allows using programming language techniques to mitigate direct dependencies, while delegating the control of the indirect dependencies to the underlying hardware. An essential element in this approach is the so-called semantic interface that stipulates a set of security and functional requirements on hardware in order for the PL-level mitigation to be sound. This talk will present the semantic interface; discuss existing practical realizations from literature, and evaluate security of this approach in a setting of active adversaries that are capable to evict caches.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Frozen Realms: draft standard support for safer JavaScript plugins</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-27-css-talk13/</link><pubDate>Fri, 27 May 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-27-css-talk13/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Mark S. Miller (Google)\&lt;br>
&lt;strong>When:&lt;/strong> 10:00, May 27 \&lt;br>
&lt;strong>Where:&lt;/strong> room EDIT 3364\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
Support ultra-fine-grain protection domains in JavaScript.
Minimizing standardization, development, explanation, and runtime costs.
Maximizing security, compatibility, simplicity, and expressiveness benefits.
See &lt;a href="https://github.com/FUDCo/proposal-frozen-realms">https://github.com/FUDCo/proposal-frozen-realms&lt;/a>&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Security of login pages on the Web: who else can know your password?</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-11-css-talk12/</link><pubDate>Wed, 11 May 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-11-css-talk12/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Steven Van Acker (Chalmers)\&lt;br>
&lt;strong>When:&lt;/strong> 14:15, May 11 \&lt;br>
&lt;strong>Where:&lt;/strong> room ED\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
Most people with an online presence these days, store large amounts of information about their lives in online web services: e-mails, pictures, medical information, &amp;hellip; To prevent unauthorised access to their personal and private information, these web services require users to authenticate and this authentication is typically done using a username and password, transmitted for verification via a login page. These login pages are critical to a user’s security. If an attacker can steal a user&amp;rsquo;s username and password, they can gain access to that user&amp;rsquo;s account easily.&lt;/p>
&lt;p>In this talk we take a look at the state of the art when it comes to security of login pages. We consider several attacker models, ranging from your typical Starbucks network attacker to sophisticated nation-state attackers.&lt;/p>
&lt;p>With these attackers in mind, we look at what the ideal login page looks like, using all security measures currently built into browsers, on top of some common sense.&lt;/p>
&lt;p>Once we know what the ideal login page looks like, we also take a look at real login pages on the Web. We analysed the login pages found on the top 100,000 most popular Internet domains and (responsibly) attacked them using simulated attacker models.&lt;/p>
&lt;p>Beware: This data is part of ongoing research and the results may shock you. You may never wish to use the Web again!&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Program behavior-based fuzzing and vulnerability discovery</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-06-css-talk9/</link><pubDate>Fri, 06 May 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-06-css-talk9/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Gustavo Grieco (CIFASIS - CONICET and VERIMAG)
&lt;strong>When:&lt;/strong> 11:00, May 6 in
&lt;strong>Where:&lt;/strong> room EDIT 8103
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
Mutational fuzzing is a powerful tool to detect vulnerabilities in software. It requires a initial set of inputs for the program to test. A traditional criteria to select inputs is to maximize code coverage in order to try to use all the instructions at least once. Unfortunately it is still insufficient to deal with real-world code like complex parsers in order to discover vulnerable conditions.&lt;/p>
&lt;p>In this talk we introduce a new approach based on program behaviors, in which traces are extracted and analyzed using Machine Learning to detect similarity between executions. Using this approach, we show how to perform vulnerability detection as well as preliminary results on how to improve seed selection for mutational fuzzing.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title> Two Can Keep a Secret, If One of Them Uses Haskell</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-04-15-css-talk8/</link><pubDate>Fri, 15 Apr 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-04-15-css-talk8/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Alejandro Russo
&lt;strong>When:&lt;/strong> 11:00 am on April 15
&lt;strong>Where:&lt;/strong> Room 3364\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;/p>
&lt;p>For several decades, researchers from different communities have
independently focused on protecting confidentiality of data. Two
distinct technologies have emerged for such purposes: Mandatory
Access Control (MAC) and Information-Flow Control (IFC)—the
former belonging to operating systems (OS) research, while the latter
to the programming languages community. These approaches
restrict how data gets propagated within a system in order to avoid
information leaks. In this scenario, the functional programming language
Haskell plays a unique privileged role: it is able to protect confidentiality via libraries.
This talk presents an (monadic) API which statically protects confidentiality even
in the presence of advanced features like exceptions, concurrency, and mutable data structures.&lt;/p>
&lt;p>This talk is based on the paper &amp;ldquo;Functional Pearl: Two Can Keep a Secret, If One of Them Uses Haskell&amp;rdquo; presented in ICFP 2015.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Recent Breakthroughs in Obfuscation</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-04-1-css-talk7/</link><pubDate>Fri, 01 Apr 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-04-1-css-talk7/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Elena Pagnin
&lt;strong>When:&lt;/strong> Friday April 1, 11:00
&lt;strong>Where:&lt;/strong> Room 8103
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>Abstract:
This talk is supposed to give an overview of the state of the art in the area of Homomorphic Encryption (HE) and Multi-Linear Maps (MLM). The final section of the talk will deal with the definition and application of indistinguishable Obfuscation.
More precisely, I will recall the syntax of FHE schemes and provide a trivial (extremely inefficient) construction of a FHE scheme. I will then cite the most significant papers in the area, highlight the trend and evolution of FHE schemes over the years (since Gentry’s first construction in 2009) and finally conclude with a slide that shows the timing required to perform homomorphic operations on a FHE scheme implemented by Halevi.
The main focus of the talk is on Muliti-Linear Maps (MLM). Roughly speaking, MLMs can be thought of as a FHE scheme in which there is no decryption, but it is possible to check if two (top level) cipher-texts are equal or not. This latter property is called zero testing and it is the main feature, but also weakness, of MLMs. I will present the second MLM candidate, the CLT13, which is based on relatively easy mathematical tools (congruences and Chinese Remainder Theorem), and its cryptanalysis (zeroing attack).
The talk will end with an introduction to obfuscation. &amp;gt;From an abstract point of view, one could think at obfuscation as a MLM without zero testing and in which only a pre-determined sequence of operations is allowed. In practice, an obfuscator is an algorithm that takes as input a program P and outputs another program O(P). such that O(P) and P have equal outputs on equal inputs and O(P) is an intelligible program.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Formal Security Analysis of Mobile and Web Applications</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-03-17-css-talk5/</link><pubDate>Thu, 17 Mar 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-03-17-css-talk5/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> &lt;a href="https://www.sps.cs.uni-saarland.de/maffei/" target="_blank" rel="noopener">Matteo Maffei&lt;/a>\&lt;br>
&lt;strong>When:&lt;/strong> Thursday, {{ page.date | date_to_long_string }}, 13:30-14:30\&lt;br>
&lt;strong>Where:&lt;/strong> Room 3364\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
In this talk, I will present two ongoing projects on the formal
verification of security properties for mobile and web
applications.&lt;/p>
&lt;p>In the first part, I will present HornDroid, a novel technique for the
static analysis of information flow properties in Android
applications. The core idea underlying HornDroid is to use Horn
clauses for soundly abstracting the semantics of Android applications
and to express security properties as a set of proof obligations that
are automatically discharged by SMT solving. This approach makes it
possible to fine-tune the analysis in order to achieve a high degree
of precision while still relying on off-the-shelf verification tools,
thereby automatically leveraging the recent advances in this field. As
a matter of fact, HornDroid outperforms in precision state-of-the-art
Android static analysis tools on benchmarks proposed by the community,
besides being orders of magnitude faster. Moreover, HornDroid is the
first static analysis tool for Android to come with a formal proof of
soundness: besides yielding correctness assurances, this proof allowed
us to identify some critical corner-cases that affect the soundness
guarantees provided by some of the previous static analysis tools for
Android.&lt;/p>
&lt;p>In the second part, I will present Michrome, a security enforcement
tool for web applications based on micro-policies. Micro-policies,
originally proposed to implement hardware-level security monitors,
constitute a flexible and general enforcement technique, based on
assigning security tags to system components and taking security
actions based on dynamic checks over these tags. In this work, we
present the first application of micro-policies to web security, by
proposing a core browser model supporting them and studying its
effectiveness at securing web sessions. In our view, web session
security requirements are expressed in terms of a simple, purely
declarative information flow policy, which is then automatically
translated into a micro-policy implementing it. This leads to a
browser-side enforcement mechanism which is elegant, sound and
flexible, while being accessible to web developers. We show how a
large class of attacks against web sessions can be uniformly and
effectively prevented by the adoption of this approach. Since we
carefully designed micro-policies with ease of deployment in mind, we
are also able to implement our proposal as a Google Chrome extension,
Michrome: our experiments show that Michrome can be easily configured
to enforce strong security policies without breaking the websites
functionality.&lt;/p>
&lt;p>&lt;strong>Biographical Note&lt;/strong>&lt;/p>
&lt;p>Matteo Maffei is professor at Saarland University and CISPA, where he
leads the Secure and Privacy-preserving Systems group. He received his
Ph.D. in Computer Science from the University of Venice in 2006.
Matteo’s research interests are in the area of formal methods for
security analysis, with a focus on cryptographic protocols, mobile
security, and web security, as well as privacy-enhancing technologies,
in particular zero-knowledge proofs, oblivious RAM, and differential
privacy. He was granted the Emmy Noether fellowship from the German
research foundation in 2009, he served in the programme committee of
more than 40 conferences, and he is currently the regular columnist on
security and privacy of the ACM SIGLOG newsletter.ill be summarized and I will discuss future research directions on data anonymization.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Anonymization of sparse multidimensional data</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-03-08-css-talk4/</link><pubDate>Tue, 08 Mar 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-03-08-css-talk4/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> &lt;a href="http://web.imis.athena-innovation.gr/~mter/" target="_blank" rel="noopener">Manolis Terrovitis&lt;/a>\&lt;br>
&lt;strong>When:&lt;/strong> Tuesday, {{ page.date | date_to_long_string }}, 15:00-12:00\&lt;br>
&lt;strong>Where:&lt;/strong> Room 8103\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
Data privacy is of increasing importance as most human activities leave digital traces in some information system. \&lt;br>
In this presentation I will talk about data anonymization and more specifically about protection against identity disclosure in the publication of sparse multidimensional data.
The presentation will explain the notion of km-anonymity and how it is applied to collections of high dimensional data like set-values and tree-structured data.
I will sketch the techniques that anonymize data through generalization, record splitting (disassociation) and algorithms that work on tree-structured data.
The advantages and disadvantages of each approach will be summarized and I will discuss future research directions on data anonymization.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Daniel Hausknecht's Licentiate presentation</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-02-29-css-talk3/</link><pubDate>Mon, 29 Feb 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-02-29-css-talk3/</guid><description>&lt;p>##Talk 1:
&lt;strong>Who:&lt;/strong> William Robertson\&lt;br>
&lt;strong>When:&lt;/strong> Monday, {{ page.date | date_to_long_string }}, 10:00-11:00\&lt;br>
&lt;strong>Where:&lt;/strong> Room 8103\&lt;br>
&lt;strong>Title:&lt;/strong> &lt;em>&lt;strong>on web malware&lt;/strong>&lt;/em> (read abstract and bio below)&lt;/p>
&lt;p>##Talk 2:
&lt;strong>Who:&lt;/strong> Daniel Hausknecht&amp;rsquo;s \&lt;br>
&lt;strong>When:&lt;/strong> Monday, {{ page.date | date_to_long_string }}, 13:15-15:00\&lt;br>
&lt;strong>Where:&lt;/strong> Room EE\&lt;br>
&lt;strong>Title:&lt;/strong> &lt;em>&lt;strong>Licentiate&amp;rsquo;s defence&lt;/strong>&lt;/em> (read abstract below)\&lt;br>
[get the slides here](url for slides)&lt;/p>
&lt;p>&lt;strong>Abstract of Robertson&amp;rsquo;s talk:&lt;/strong>
The modern Web is heavily reliant on JavaScript for implementing
client-side web applications and extending browser functionality. And
yet, despite varied efforts to isolate, tame, or analyze it, JavaScript
continues to enable new attacks against the web platform.&lt;/p>
&lt;p>In this talk, I will present recent work on bypassing browser security
controls via a novel form of code reuse, and discuss a lightweight
static analysis to detect this class of vulnerabilities. Then, I will
present ZigZag, a system for hardening JavaScript-based web applications
against client-side validation vulnerabilities that relies on invariant
detection and efficient instrumentation.&lt;/p>
&lt;p>&lt;strong>Biographical Note&lt;/strong>
William Robertson is an assistant professor of Computer Science at
Northeastern University in Boston, MA, and co-directs the NEU Systems
Security Lab. His research revolves around improving the security of
operating systems, mobile devices, and the web, making use of techniques
such as security by design, program analysis, and anomaly detection.&lt;/p>
&lt;p>&lt;strong>Abstract of Hausknecht&amp;rsquo;s talk:&lt;/strong>&lt;/p></description></item><item><title>Towards more secure and usable text passwords</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-01-28-css-talk2/</link><pubDate>Thu, 28 Jan 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-01-28-css-talk2/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Prof. &lt;a href="http://www.ece.cmu.edu/~lbauer/bio.html" target="_blank" rel="noopener">Lujo Bauer&lt;/a> from Carnegie Mellon University\&lt;br>
&lt;strong>When:&lt;/strong> Thursday, {{ page.date | date_to_long_string }}, 15:00\&lt;br>
&lt;strong>Where:&lt;/strong> Room EA\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>
Many security problems arise at the interface between computer systems and their users. One set of such problems relates to authentication and text-based passwords, which despite numerous shortcomings and attacks remain the dominant authentication method in computer systems.
\&lt;br>
Is pa$$w0rd1 a good password or a bad one? For several years, we&amp;rsquo;ve been studying how to help users create passwords that are hard for attackers to crack, but are still easy for users to remember and use. A key challenge in this work was to develop and validate a methodology for collecting passwords and assessing their strength and usability. I&amp;rsquo;ll discuss our approach, and how we applied it to over 50,000 participants to study the effects of password-composition policies, password-strength meters, and detailed, step-by-step feedback and guidance during the password creation policies.&lt;/p></description></item><item><title>Establishing and Maintaining Root of Trust on Commodity Computer Systems</title><link>https://www.cse.chalmers.se/research/group/security/event/2015/2015-11-27-css-talk1/</link><pubDate>Fri, 27 Nov 2015 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2015/2015-11-27-css-talk1/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> &lt;a href="http://users.ece.cmu.edu/~virgil/" target="_blank" rel="noopener">Virgil Gligor&lt;/a> CMU\&lt;br>
&lt;strong>When:&lt;/strong> Friday, {{ page.date | date_to_long_string }}, 11:00-12:00\&lt;br>
&lt;strong>Where:&lt;/strong> Room 8103\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
Suppose that a trustworthy program must be booted on a commodity system that may contain persistent malware. For example, a formally verified micro-kernel, micro-hypervisor, or a subsystem obtained from a trustworthy provider must be booted on a computer system that runs Windows, Linux, or Android applications. Establishing root of trust assures the user that either the system is in a malware-free state in which the trustworthy-program boot takes place or the presence of malware is discovered, with high probability. Obtaining such assurance is challenging because malware can survive in system state across repeated secure- and trusted-boot operations. These operations do not always have malware-unmediated access to device memories; e.g., memories of bring-your-own devices (e.g., keyboards, consoles, printers, routers), and sometimes even disk controllers. They certainly have no unmediated access to all non-volatile memories of interconnected components of a personal system; e.g., components of home systems, autos. To date, concrete assurance for root-of-trust establishment has not been obtained on commodity systems that scale to large configurations.
\&lt;br>
Establishing root of trust makes all persistent malware ephemeral and forces the adversary to repeat the malware-insertion attack, perhaps at some added cost. Nevertheless, some malware-controlled software can always be assumed to exist in commodity operating systems and applications. The inherent size and complexity of their operating systems and applications (aka the “giants”) render them vulnerable to successful adversary attacks. In contrast, small and simple software components with rather limited function and high-assurance layered security properties (aka the “wimps”) can be resistant to adversary attacks.
Maintaining root of trust assures a user that a commodity computer’s wimps are isolated from, and safely co-exist with, adversary-controlled giants. To survive, secure wimps must use services of, or compose with, insecure giants. This appears to be “paradoxical:” wimps can counter all adversary attacks but survive only if they use giants’ adversary-controlled services from which they have to defend themselves.
\&lt;br>
I this seminar, I will illustrate the challenges of root-of-trust establishment via “verifiable boot” operations that do not require secrets, TPMs, or adversary bounds. Then, I will present a method to define a wimp’s adversary accurately and completely using a structure found in cryptographic protocols. A consequence of such definitions is the ability to produce partial orders on adversary attacks. Finally, I will present secure wimp composition with giants, via two examples of experimental systems (i.e., on-demand isolated I/O channels and a trusted display service) designed and implemented at CMU CyLab.&lt;/p>
&lt;p>&lt;strong>Biographical Note&lt;/strong>
Virgil D. Gligor received his B.Sc., M.Sc., and Ph.D. degrees from the University of California at Berkeley. He taught at the University of Maryland between 1976 and 2007, and is currently a Professor of ECE at Carnegie Mellon University. Between 2007 and 2015 he was the co-Director of CyLab. Over the past forty years, his research interests ranged from access control mechanisms, penetration analysis, and denial-of-service protection, to cryptographic protocols and applied cryptography. Gligor was an editorial board member of several ACM and IEEE journals and the Editor in Chief of the IEEE Transactions on Dependable and Secure Computing. He received the 2006 National Information Systems Security Award jointly given by NIST and NSA, the 2011 Outstanding Innovation Award of the ACM SIG on Security Audit and Control, and the 2013 Technical Achievement Award of the IEEE Computer Society.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item></channel></rss>