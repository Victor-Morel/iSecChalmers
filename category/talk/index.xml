<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>talk | Chalmers Security Lab</title><link>iSec/category/talk/</link><atom:link href="iSec/category/talk/index.xml" rel="self" type="application/rss+xml"/><description>talk</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 08 Oct 2021 00:00:00 +0000</lastBuildDate><image><url>/iSec/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png</url><title>talk</title><link>iSec/category/talk/</link></image><item><title>Practical Data Access Minimization in Trigger-Action Platforms</title><link>iSec/event/2021/2021-10-08-css-talk48/</link><pubDate>Fri, 08 Oct 2021 00:00:00 +0000</pubDate><guid>iSec/event/2021/2021-10-08-css-talk48/</guid><description/></item><item><title>Seyed Mohammad Mehdi Ahmadpanah's Licentiate: Securing Software in the Presence of Third-Party Modules</title><link>iSec/event/2021/2021-10-01-css-talk47/</link><pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate><guid>iSec/event/2021/2021-10-01-css-talk47/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Seyed Mohammad Mehdi Ahmadpanah\
&lt;strong>When:&lt;/strong> 15:15 Friday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> &lt;a href="https://chalmers.zoom.us/j/61204218636?pwd=S3JxUEZnRTdqU0M3bXA0TDFEblhUQT09" target="_blank" rel="noopener">Zoom&lt;/a>\
&lt;strong>Details about the thesis:&lt;/strong> &lt;a href="https://research.chalmers.se/en/publication/?id=525880" target="_blank" rel="noopener">https://research.chalmers.se/en/publication/?id=525880&lt;/a>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
{{ page.teaser }}&lt;/p>
&lt;p>&lt;a href="https://research.chalmers.se/en/publication/?id=525880" target="_blank" rel="noopener">Details about the thesis and related publications&lt;/a>.&lt;/p></description></item><item><title>Simone Fischer-Hübner's Honorary Doctorate Lecture:
Challenges of User-centric Privacy Enhancing Technologies</title><link>iSec/event/2021/2021-09-17-css-talk46/</link><pubDate>Fri, 17 Sep 2021 00:00:00 +0000</pubDate><guid>iSec/event/2021/2021-09-17-css-talk46/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> &lt;a href="https://simone.hotell.kau.se/" target="_blank" rel="noopener">Prof. Simone Fischer-Hübner&lt;/a>\
&lt;strong>When:&lt;/strong> 16:30–17:00 on Friday {{ page.date | date_to_long_string }}.\
Other honorary doctors will speak before and after Simone - feel free
to attend the whole event 4pm-6pm! (If you attend in person, please do
come at 4pm.)\
&lt;strong>Where:&lt;/strong> Chalmersska huset\
(limited seats, register via &lt;a href="mailto:events@chalmers.se">events@chalmers.se&lt;/a> to attend in person)\
&lt;strong>Where (online):&lt;/strong> &lt;a href="https://www.youtube.com/watch?v=njiEDbx_eXA" target="_blank" rel="noopener">on YouTube&lt;/a>\
&lt;strong>Title:&lt;/strong> Challenges of User-centric Privacy Enhancing Technologies&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
{{ page.teaser }}&lt;/p>
&lt;p>Further info on the event
&lt;a href="https://www.chalmers.se/en/about-chalmers/calendar/Pages/Watch-the-Chalmers%27-Honorary-Doctors%27-Speech.aspx" target="_blank" rel="noopener">in English&lt;/a>
and
&lt;a href="https://www.chalmers.se/sv/om-chalmers/kalendarium/Sidor/Lyssna-till-Chalmers-hedersdoktorer.aspx" target="_blank" rel="noopener">in Swedish&lt;/a>.&lt;/p></description></item><item><title>Boel Nelson's PhD Defense: Differential Privacy — A Balancing Act</title><link>iSec/event/2021/2021-06-18-css-talk45/</link><pubDate>Fri, 18 Jun 2021 00:00:00 +0000</pubDate><guid>iSec/event/2021/2021-06-18-css-talk45/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Boel Nelson\
&lt;strong>When:&lt;/strong> 14:00 Friday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> &lt;a href="https://chalmers.zoom.us/j/69493968177?pwd=cFF3ZXAvdnRPRlVkc1U4a1hCQi9kUT09" target="_blank" rel="noopener">Zoom&lt;/a>\
&lt;strong>Password:&lt;/strong> 1999\
&lt;strong>Details about the thesis:&lt;/strong> &lt;a href="https://research.chalmers.se/en/publication/523824" target="_blank" rel="noopener">https://research.chalmers.se/en/publication/523824&lt;/a>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
{{ page.teaser }}&lt;/p>
&lt;p>&lt;a href="https://research.chalmers.se/en/publication/523824" target="_blank" rel="noopener">Details about the thesis and related publications&lt;/a>.&lt;/p></description></item><item><title>High-Assurance Cryptography Software in the Spectre Era</title><link>iSec/event/2021/2021-06-11-css-talk44/</link><pubDate>Fri, 11 Jun 2021 00:00:00 +0000</pubDate><guid>iSec/event/2021/2021-06-11-css-talk44/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Gilles Barthe\
&lt;strong>When:&lt;/strong> 13:15 - 14:15 Friday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> &lt;a href="https://chalmers.zoom.us/j/65786317139?pwd=U1FlMks3THpNNG1WaFRJNkJxQXdBQT09" target="_blank" rel="noopener">Zoom&lt;/a>\
&lt;strong>Password:&lt;/strong> 485011\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
{{ page.teaser }}&lt;/p>
&lt;p>To appear in the Proceedings of the IEEE Symposium on Security and
Privacy, 2021. &lt;a href="https://eprint.iacr.org/2020/1104" target="_blank" rel="noopener">https://eprint.iacr.org/2020/1104&lt;/a>&lt;/p></description></item><item><title>A different perspective on libraries for information-flow control</title><link>iSec/event/2021/2021-06-04-css-talk43/</link><pubDate>Fri, 04 Jun 2021 00:00:00 +0000</pubDate><guid>iSec/event/2021/2021-06-04-css-talk43/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Carlos Tomé Cortiñas\
&lt;strong>When:&lt;/strong> 13:15 - 14:15 Friday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> &lt;a href="https://chalmers.zoom.us/j/65786317139?pwd=U1FlMks3THpNNG1WaFRJNkJxQXdBQT09" target="_blank" rel="noopener">Zoom&lt;/a>\
&lt;strong>Password:&lt;/strong> 485011\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
{{ page.teaser }}&lt;/p></description></item><item><title>Fuzz Testing Automotive Systems - Process and Practice</title><link>iSec/event/2021/2021-05-27-css-talk42/</link><pubDate>Thu, 27 May 2021 00:00:00 +0000</pubDate><guid>iSec/event/2021/2021-05-27-css-talk42/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Dennis Kengo Oka\
&lt;strong>When:&lt;/strong> 10:00 - 11:00 Thursday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> &lt;a href="https://chalmers.zoom.us/j/65786317139?pwd=U1FlMks3THpNNG1WaFRJNkJxQXdBQT09" target="_blank" rel="noopener">Zoom&lt;/a>\
&lt;strong>Password:&lt;/strong> 485011\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
{{ page.teaser }}&lt;/p></description></item><item><title>Can we enforce GDPR principles via information flow control?</title><link>iSec/event/2021/2021-05-07-css-talk40/</link><pubDate>Fri, 07 May 2021 00:00:00 +0000</pubDate><guid>iSec/event/2021/2021-05-07-css-talk40/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Sandro Stucki\
&lt;strong>When:&lt;/strong> 13:15 - 14:15 Friday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> &lt;a href="https://chalmers.zoom.us/my/securityseminar?pwd=UHBtVWtvSUs0STNoYTdiUmwreGRTUT09" target="_blank" rel="noopener">Zoom&lt;/a>\
&lt;strong>Password:&lt;/strong> 143454\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
{{ page.teaser }}&lt;/p></description></item><item><title>A Quantale of Information</title><link>iSec/event/2021/2021-04-29-css-talk39/</link><pubDate>Thu, 29 Apr 2021 00:00:00 +0000</pubDate><guid>iSec/event/2021/2021-04-29-css-talk39/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> David Sands\
&lt;strong>When:&lt;/strong> 13:15 - 14:15 Thursday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> &lt;a href="https://chalmers.zoom.us/my/securityseminar?pwd=UHBtVWtvSUs0STNoYTdiUmwreGRTUT09" target="_blank" rel="noopener">Zoom&lt;/a>\
&lt;strong>Password:&lt;/strong> 143454\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>Joint work with Sebastian Hunt, City, University of London. (Conditionally accepted to CSF 2021.)&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
{{ page.teaser }}&lt;/p></description></item><item><title>On the Evolution of IT Security</title><link>iSec/event/2021/2021-04-16-css-talk38/</link><pubDate>Fri, 16 Apr 2021 00:00:00 +0000</pubDate><guid>iSec/event/2021/2021-04-16-css-talk38/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> David Jacoby, Kaspersky Lab\
&lt;strong>When:&lt;/strong> 13:15 - 14:15 Friday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> &lt;a href="https://chalmers.zoom.us/my/securityseminar?pwd=UHBtVWtvSUs0STNoYTdiUmwreGRTUT09" target="_blank" rel="noopener">Zoom&lt;/a>\
&lt;strong>Password:&lt;/strong> 143454\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
IT security is an ever important topic. From pioneering to modern times, new security problems keep being discovered. Still, many problems stem from similar flaws. As such, solutions to security problems often involve applying old solutions to new settings. In this talk, we elaborate on the nature of security problems, where they arise, and what methodology is needed to tackle such problems.&lt;/p>
&lt;p>In addition, we also discuss common misconceptions about IT security, and, building upon years of experience, learn how to think like a hacker.&lt;/p>
&lt;p>&lt;strong>Speaker Bio:&lt;/strong>\
David Jacoby is a senior security researcher at Kaspersky Lab. David has worked with IT security for over 25 years, and his fields of expertise include vulnerability and threat research, product and security audits, penetration tests, and security research. In his day to day job, David works on improving awareness of the current and future threats and vulnerabilities to which both consumers and large enterprises are exposed and fight cybercrime.&lt;/p>
&lt;p>In addition, David worked as the technical advisor for the continuation of the Millennium books written by David Lagercrantz. He has also been included in multiple other books such as &amp;ldquo;A Guide to Kernel Exploitation: Attacking the Core&amp;rdquo;, &amp;ldquo;Generation 500&amp;rdquo; and &amp;ldquo;Svenska Hackare&amp;rdquo;. Additional to being an advisor for book projects David is also often seen on TV in programs such as “Stoppa Tjuven” and TV4 Nyhetsmorgon.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>SoK: Chasing Accuracy and Privacy, and Catching Both in Differentially Private Histogram Publication</title><link>iSec/event/2021/2021-04-09-css-talk37/</link><pubDate>Fri, 09 Apr 2021 00:00:00 +0000</pubDate><guid>iSec/event/2021/2021-04-09-css-talk37/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Boel Nelson\
&lt;strong>When:&lt;/strong> 13:15 - 14:15 Friday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> &lt;a href="https://chalmers.zoom.us/my/securityseminar?pwd=UHBtVWtvSUs0STNoYTdiUmwreGRTUT09" target="_blank" rel="noopener">Zoom&lt;/a>\
&lt;strong>Password:&lt;/strong> \
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
Histograms and synthetic data are of key importance in data analysis. However, researchers have shown that even aggregated data such as histograms, containing no obvious sensitive attributes, can result in privacy leakage. To enable data analysis, a strong notion of privacy is required to avoid risking unintended privacy violations.&lt;/p>
&lt;p>Such a strong notion of privacy is differential privacy, a statistical notion of privacy that makes privacy leakage quantifiable. The caveat regarding differential privacy is that while it has strong guarantees for privacy, privacy comes at a cost of accuracy. Despite this trade-off being a central and important issue in the adoption of differential privacy, there exists a gap in the literature regarding providing an understanding of the trade-off and how to address it appropriately.&lt;/p>
&lt;p>Through a systematic literature review (SLR), we investigate the state-of-the-art within accuracy improving differentially private algorithms for histogram and synthetic data publishing. Our contribution is two-fold: 1) we identify trends and connections in the contributions to the field of differential privacy for histograms and synthetic data and 2) we provide an understanding of the privacy/accuracy trade-off challenge by crystallizing different dimensions to accuracy improvement. Accordingly, we position and visualize the ideas in relation to each other and external work, and deconstruct each algorithm to examine the building blocks separately with the aim of pinpointing which dimension of accuracy improvement each technique/approach is targeting. Hence, this systematization of knowledge (SoK) provides an understanding of in which dimensions and how accuracy improvement can be pursued without sacrificing privacy.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Towards new fuzzing frontiers: exploring the boundaries of testing</title><link>iSec/event/2021/2021-03-18-css-talk36/</link><pubDate>Thu, 18 Mar 2021 00:00:00 +0000</pubDate><guid>iSec/event/2021/2021-03-18-css-talk36/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Mathias Payer, EPFL\
&lt;strong>When:&lt;/strong> 13:15 - 14:15 Thursday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> &lt;a href="https://chalmers.zoom.us/j/65826436680" target="_blank" rel="noopener">Zoom&lt;/a> (Note, not the usual zoom room!)\
&lt;strong>Password:&lt;/strong> \
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
Memory corruption plagues systems since the dawn of computing. Despite the rise of strong mitigations, exploits are still prevalent. This situation calls for automatic software testing techniques that discover reachable vulnerabilities before any attacker. We will disuss types of bugs, where to find them, and how to prune them.&lt;/p>
&lt;p>Finding and fixing bugs is the only way to prohibit all exploitation vectors. We develop fuzzing techniques that follow an adversarial approach, focusing on the exposed attack surface and exploring potentially reachable vulnerabilities. In this talk, we will discuss two aspects of fuzzing hard to reach code: (i) learning how code is exposed to attacker-controlled input and (ii) testing drivers that interact with exposed peripherals. First, we assess the threat surface
by characterizing the potential computational power that a vulnerability gives. In a multi-step process we follow the flow of information and synthesize complex fuzzing stubs to test specific code sequences. Second, by providing a custom-tailored emulation environment we create virtual mock devices that allow fuzzing the peripheral/driver interface. In these projects we develop new techniques to test different kinds of hard to reach code and exposed large amounts of vulnerabilities in Android and the Linux kernel.&lt;/p>
&lt;p>&lt;strong>Speaker Bio:&lt;/strong>\
Mathias Payer is a security researcher and assistant professor at EPFL, leading the HexHive group. His research focuses on protecting applications in the presence of vulnerabilities, with a focus on memory corruption and type violations. He is interested in software security, system security, binary exploitation, effective mitigations, fault isolation/privilege separation, strong sanitization, and software testing (fuzzing) using a combination of binary analysis and
compiler-based techniques. Research in the HexHive group is generously supported by the ERC, SNSF, DARPA, ONR, AFOSR, or NSF, as well as several industry partners. Follow him on Twitter @gannimo. Details about his group are at &lt;a href="https://hexhive.epfl.ch" target="_blank" rel="noopener">https://hexhive.epfl.ch&lt;/a>&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Practical secure compilation using WebAssembly</title><link>iSec/event/2021/2021-03-12-css-talk35/</link><pubDate>Fri, 12 Mar 2021 00:00:00 +0000</pubDate><guid>iSec/event/2021/2021-03-12-css-talk35/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Deian Stefan, University of California, San Diego \
&lt;strong>When:&lt;/strong> 17:00 - 18:00 Friday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> &lt;a href="https://chalmers.zoom.us/my/securityseminar?pwd=UHBtVWtvSUs0STNoYTdiUmwreGRTUT09" target="_blank" rel="noopener">Zoom&lt;/a>\
&lt;strong>Password:&lt;/strong> 143454 \
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
WebAssembly (Wasm) is a portable bytecode originally designed to safely run native code (e.g., C/C++ and Rust) in the browser. Since its initial design, though, Wasm has been increasingly used to sandbox untrusted code outside the browser. For example, Fastly and Cloudflare use Wasm to sandbox client applications running on their edge clouds, and with Mozilla we are using Wasm to sandbox libraries in Firefox. In this talk I will describe this effort and our effort to make Wasm more secure (e.g., by hardening Wasm against compiler bugs and Spectre attacks).&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Liquid Information Flow Control</title><link>iSec/event/2021/2021-03-05-css-talk34/</link><pubDate>Fri, 05 Mar 2021 00:00:00 +0000</pubDate><guid>iSec/event/2021/2021-03-05-css-talk34/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Nadia Polikarpova, University of California, San Diego \
&lt;strong>When:&lt;/strong> 17:00 - 18:00 Friday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> &lt;a href="https://chalmers.zoom.us/my/securityseminar?pwd=UHBtVWtvSUs0STNoYTdiUmwreGRTUT09" target="_blank" rel="noopener">Zoom&lt;/a>\
&lt;strong>Password:&lt;/strong> 143454 \
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
Modern applications handle sensitive user data in complex ways, subject to increasingly complex security policies. A promising approach to enforcing these policies is to use Information Flow Control (IFC) frameworks, which separate policy specification from the application code and automatically enforce policies either dynamically (at run time) or statically (at compile time). While static enforcement is desirable because it catches errors early and avoids run-time overhead, existing static IFC frameworks either lack support for expressive data-dependent policies (necessary in modern applications), or require manual proofs or annotations to be strewed throughout the application code.&lt;/p>
&lt;p>In this talk I will present Lifty, a static IFC framework that overcomes the limitations of existing static approaches. A Lifty programmer annotates the sources of sensitive data with expressive, data-dependent security policies, and Lifty statically and automatically verifies that the application handles the data according to the policies. Moreover, if verification fails, Lifty suggests a provably correct repair, thereby easing the programmer burden of implementing policy enforcing code throughout the application. The main insight behind Lifty is to encode information flow control using liquid types, an expressive yet decidable type system. Liquid types enable fully automatic checking of complex policies, and power our repair mechanism via type-driven error localization and patch synthesis.&lt;/p>
&lt;p>&lt;strong>Speaker Bio:&lt;/strong>\
Nadia Polikarpova is an assistant professor at UC San Diego, and a member of the Programming Systems group. She received her Ph.D. in Computer Science from ETH Zurich in 2014, and then spent a couple years as a postdoctoral researcher at MIT. Nadia&amp;rsquo;s research interests are in program synthesis, program verification, and type systems. She is a 2020 Sloan Fellow, and a recipient of the 2020 NSF Career Award and the 2020 Intel Rising Stars Award.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>w0RLd w1dE W3b - The dangers of web security inconsistencies</title><link>iSec/event/2021/2021-02-26-css-talk33/</link><pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate><guid>iSec/event/2021/2021-02-26-css-talk33/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Stefano Calzavara, Università Ca' Foscari Venezia\
&lt;strong>When:&lt;/strong> 13:15 - 14:15 Friday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> &lt;a href="https://chalmers.zoom.us/my/securityseminar?pwd=UHBtVWtvSUs0STNoYTdiUmwreGRTUT09" target="_blank" rel="noopener">Zoom&lt;/a>\
&lt;strong>Password:&lt;/strong> 143454 \
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
Web application security is a complicated matter. To assist site operators in secure web application development, browser vendors offer client-side security mechanisms designed to offer robust protection against common threats. Unfortunately, prior research showed that these mechanisms are often ineffective in practice for several reasons. In this talk, I provide yet another perspective on why client-side security mechanisms often fail, by focusing on the problem of inconsistent configuration. Inconsistencies not only affect web application security, but might also bias the results of web security measurements. In particular, I identify inconsistencies in the adoption of popular client-side security mechanisms like CSP, HSTS and cookie security attributes, which motivates the relevance of this issue and the need for further research on it.&lt;/p>
&lt;p>&lt;strong>Speaker Bio:&lt;/strong>\
Stefano Calzavara is a tenure-track assistant professor at Università Ca' Foscari Venezia, Italy. He holds a National Scientific License (ASN) for the role of Associate Professor in Computer Science and Information Engineering from the end of 2019.&lt;/p>
&lt;p>Stefano&amp;rsquo;s research focuses on formal methods, computer security and their intersection, with a strong emphasis on web security. Stefano has published 46 papers on these topics at widely recognized international conferences and journals, including IEEE S&amp;amp;P, ACM CCS, NDSS, USENIX Security, WWW, IEEE CSF, ESOP, ACM CSUR, ACM TOPLAS and ACM TWEB. He is pleased to regularly serve in the program committees of a number of scientific events, including flagship conferences like ACM CCS, USENIX Security, WWW, IEEE EuroS&amp;amp;P and IEEE CSF.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Let's not make a fuzz about it</title><link>iSec/event/2021/2021-02-19-css-talk32/</link><pubDate>Fri, 19 Feb 2021 00:00:00 +0000</pubDate><guid>iSec/event/2021/2021-02-19-css-talk32/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Alejandro Russo\
&lt;strong>When:&lt;/strong> 13:15 - 14:15 Friday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> &lt;a href="https://chalmers.zoom.us/my/securityseminar?pwd=UHBtVWtvSUs0STNoYTdiUmwreGRTUT09" target="_blank" rel="noopener">Zoom&lt;/a>\
&lt;strong>Password:&lt;/strong> 143454 \
&lt;strong>Title: Let&amp;rsquo;s not make a fuzz about it&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
The work of Fuzz has pioneered the use of functional programming languages where types allow reasoning about the sensitivity of programs. Fuzz and subsequent work (e.g., DFuzz and Duet) use technical devices like linear types, modal types, and partial evaluation. These features usually require the design of a new programming language from scratch - a major task on its own! While these features are part of the classical toolbox of programming languages, they are often rather obscure for non-programming language experts. In this work-in-progress talk, we explore a different direction. We propose the design of a library capable of calculating the sensitivity of programs.&lt;/p>
&lt;p>The library is built on a novel use of polymorphism to represent (and prove) the sensitivity of functions together with
the use of type constraints and type-level natural numbers. We show how our approach can be used to reason about the sensitivity of classical examples working over vectors, such as sum, map, and sort - we leave reasoning about more complex programs for future work. We will also present some future directions to explore together with some
flaws that our approach that we need to overcome.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>HMAC and 'Secure Preferences': Revisiting Chromium-Based Browsers Security</title><link>iSec/event/2021/2021-02-05-css-talk31/</link><pubDate>Fri, 05 Feb 2021 00:00:00 +0000</pubDate><guid>iSec/event/2021/2021-02-05-css-talk31/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Pablo Picazo-Sanchez\
&lt;strong>When:&lt;/strong> 13:15 - 14:15 Friday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> &lt;a href="https://chalmers.zoom.us/my/securityseminar?pwd=UHBtVWtvSUs0STNoYTdiUmwreGRTUT09" target="_blank" rel="noopener">Zoom&lt;/a>\
&lt;strong>Password:&lt;/strong> 143454 \
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
Google disabled years ago the possibility to freely modify some internal configuration parameters, so options like silently (un)install browser extensions, changing the home page or the search engine were banned. This capability was as simple as adding/removing some lines from a plain text file called Secure Preferences File automatically created by Chromium the first time it was launched. Concretely, Google introduced a security mechanism based on a cryptographic algorithm named HMAC to avoid users and applications other than the browser modifying the Secure Preferences File This paper demonstrates that it is possible to perform browser hijacking, browser extension fingerprinting, and remote code execution attacks as well as silent browser extensions (un)installation by coding a platform-independent proof-of-concept changeware that exploits the HMAC, allowing for free modification of the Secure Preferences File Last but not least, we analyze the security of the four most important Chromium-based browsers: Brave, Chrome, Microsoft Edge, and Opera, concluding that all of them suffer from the same security pitfall.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Security Assurance Cases for Road Vehicles: an Industry Perspective</title><link>iSec/event/2021/2021-01-29-css-talk30/</link><pubDate>Fri, 29 Jan 2021 00:00:00 +0000</pubDate><guid>iSec/event/2021/2021-01-29-css-talk30/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Mazen Mohamad\
&lt;strong>When:&lt;/strong> 13:15 - 14:15 Friday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> &lt;a href="https://chalmers.zoom.us/my/securityseminar?pwd=UHBtVWtvSUs0STNoYTdiUmwreGRTUT09" target="_blank" rel="noopener">Zoom&lt;/a>\
&lt;strong>Password:&lt;/strong> 143454 \
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
Assurance cases are structured arguments that are commonly used to reason about the safety of a product or service. Currently, there is an ongoing push towards using assurance cases for also cybersecurity, especially in safety-critical domains, like automotive. While the industry is faced with the challenge of defining a sound methodology to build security assurance cases, the state of the art is rather immature. Therefore, we have conducted a thorough investigation of the (external) constraints and (internal) needs that security assurance cases have to satisfy in the context of the automotive industry. This has been done in the context of two large automotive companies in Sweden. The end result is a set of recommendations that automotive companies can apply in order to define security assurance cases that are (i) aligned with the constraints imposed by the existing and upcoming standards and regulations and (ii)harmonized with the internal product development processes and organizational practices. We expect the results to be also of interest for product companies in other safety-critical domains, like healthcare, transportation, and so on.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>An Overview of Vehicular Security</title><link>iSec/event/2021/2021-01-22-css-talk29/</link><pubDate>Fri, 22 Jan 2021 00:00:00 +0000</pubDate><guid>iSec/event/2021/2021-01-22-css-talk29/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Tomas Olovsson \
&lt;strong>When:&lt;/strong> 13:30 - 14:30 Friday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> &lt;a href="https://chalmers.zoom.us/my/securityseminar?pwd=UHBtVWtvSUs0STNoYTdiUmwreGRTUT09" target="_blank" rel="noopener">Zoom&lt;/a>\
&lt;strong>Password:&lt;/strong> 143454 \
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
This talk will give a first overview of research and activities trending in automotive security. We will look at future cooperative vehicle safety systems where cellular communications (i.e., 4G, 5G) and IEEE 802.11p are technologies enabling Vehicle-to-everything (V2X) communications. The talk will focus on security and highlight some attacks and problem areas and motivate why specific and tailored security solutions are necessary in this domain.&lt;/p>
&lt;p>We will have a look at real attacks and security problems, current state of automotive security research including the 5G ecosystem, quantum-resistant ciphers, intrusion detection systems and other &amp;ldquo;hot&amp;rdquo; research areas in this domain. The talk will be rather general paving the ground for more specific and detailed presentations in this seminar series.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Decentralized Action Integrity for Trigger-Action Platforms</title><link>iSec/event/2020/2020-11-20-css-talk28/</link><pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate><guid>iSec/event/2020/2020-11-20-css-talk28/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Earlence Fernandes \
&lt;strong>When:&lt;/strong> 16:00 - 17:00 Friday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> &lt;a href="https://chalmers.zoom.us/j/62000149203" target="_blank" rel="noopener">https://chalmers.zoom.us/j/62000149203&lt;/a>\
&lt;strong>Password:&lt;/strong> 141558 \
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
Trigger-Action platforms are web-based systems that enable users to create automation rules by stitching together online services representing digital and physical resources using OAuth tokens. Unfortunately, these platforms introduce a long range large-scale security risk: If they are compromised, an attacker can misuse the OAuth tokens belonging to a large number of users to arbitrarily manipulate their devices and data. To tackle this issue, we introduce Decentralized Action Integrity, a security principle that prevents an untrusted trigger-action platform from misusing compromised OAuth tokens in ways that are inconsistent with any given user&amp;rsquo;s set of trigger-action rules.&lt;/p>
&lt;p>&lt;strong>Speaker Bio:&lt;/strong>\
&lt;a href="http://www.earlence.com/" target="_blank" rel="noopener">Earlence Fernandes&lt;/a> is an Assistant Professor in the Computer Sciences department at UW Madison. His research interests are in emerging cyber-physical systems like smart homes, buildings and vehicles. He has been awarded two best papers (at Oakland and IEEE SecDev) for his work on smart homes. He earned his PhD at the University of Michigan in 2017.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>When Good Components Go Bad: Formally Secure Compilation Despite Dynamic Compromise</title><link>iSec/event/2019/2019-12-05-css-talk27/</link><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid>iSec/event/2019/2019-12-05-css-talk27/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Catalin Hritcu from Inria Paris, France \
&lt;strong>When:&lt;/strong> 14:00 - 15:00 Thursday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> Room ES52, Linsen (Maskingränd 2).\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;/p>
&lt;p>We propose a new formal criterion for evaluating secure
compartmentalization schemes for unsafe languages like C and C++,
expressing end-to-end security guarantees for software components that
may become compromised after encountering undefined behavior&amp;mdash;for
example, by accessing an array out of bounds. Our criterion is the
first to model dynamic compromise in a system of mutually distrustful
components with clearly specified privileges. It articulates how each
component should be protected from all the others&amp;mdash;in particular,
from components that have encountered undefined behavior and become
compromised.
To illustrate the model, we construct a secure compilation chain for a
small unsafe language with buffers, procedures, and components,
targeting a simple abstract machine with built-in
compartmentalization. We propose a novel proof technique and give a
machine-checked proof in Coq that this compiler satisfies our secure
compilation criterion. Finally, we show that the protection guarantees
offered by the compartmentalized abstract machine can be achieved at
the machine-code level using either software fault isolation or a
tag-based reference monitor.&lt;/p>
&lt;p>&lt;strong>Speaker Bio:&lt;/strong>\&lt;/p>
&lt;p>&lt;a href="https://prosecco.gforge.inria.fr/personal/hritcu" target="_blank" rel="noopener">Catalin Hritcu&lt;/a> is a
researcher at Inria Paris where he works on security foundations. He is
particularly interested in formal methods for security (secure compilation,
compartmentalization, memory safety, security protocols, integrity, information
flow), programming languages (program verification, proof assistants, type
systems, semantics, formal metatheory, certified tools, property-based testing),
and the design and verification of security-critical systems (reference
monitors, secure compilation chains, secure hardware). He was awarded an ERC
Starting Grant on formally secure compilation
&lt;a href="https://secure-compilation.github.io" target="_blank" rel="noopener">(https://secure-compilation.github.io)&lt;/a>,
and is also actively involved in the design of the F* verification system
&lt;a href="https://www.fstar-lang.org/" target="_blank" rel="noopener">(https://www.fstar-lang.org/)&lt;/a>, which is used for
building a formally verified HTTPS stack
&lt;a href="https://project-everest.github.io" target="_blank" rel="noopener">(https://project-everest.github.io)&lt;/a>. Catalin
received a PhD from Saarland University in Saarbrücken, a Habilitation from ENS
Paris, and was previously also a Research Associate at University of
Pennsylvania and a Visiting Researcher at Microsoft Research Redmond.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Risk Analysis of Privacy Policies</title><link>iSec/event/2019/2019-11-22-css-talk26/</link><pubDate>Fri, 22 Nov 2019 00:00:00 +0000</pubDate><guid>iSec/event/2019/2019-11-22-css-talk26/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Raúl Pardo Jimenez from IT University of Copenhagen, Denmark \
&lt;strong>When:&lt;/strong> 11:00 - 12:00 Friday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> Room 8103, EDIT building.\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;/p>
&lt;p>In this talk, I present an approach to enhance informed consent
for the processing of personal data. The approach relies on a
privacy policy language used to express, compare and analyze
privacy policies. I describe a tool that automatically reports
the privacy risks associated with a given privacy policy in order
to enhance data subjects' awareness and to allow them to make
more informed choices. The risk analysis of privacy policies is
illustrated with an IoT example.&lt;/p>
&lt;p>This talk is based on work published at
DBSec19, and a paper under submission to the Journal of Computer
Security. You can find an publicly available version of the paper here
&lt;a href="https://hal.inria.fr/hal-02067924v2" target="_blank" rel="noopener">https://hal.inria.fr/hal-02067924v2&lt;/a>&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>The Simplest Multi-key Linearly Homomorphic Signature Scheme</title><link>iSec/event/2019/2019-10-17-css-talk25/</link><pubDate>Thu, 17 Oct 2019 00:00:00 +0000</pubDate><guid>iSec/event/2019/2019-10-17-css-talk25/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Elena Pagnin from Aarhus University, Denmark \
&lt;strong>When:&lt;/strong> 10:00 - 11:00 Thursday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> Room 8103, EDIT building.\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
We consider the problem of outsourcing computation on data authenticated by different users.
Our aim is to describe and implement the simplest possible solution to provide data integrity in cloud-based scenarios.
Concretely, our multi-key linearly homomorphic signature scheme (mklhs) allows users to upload signed data on a server,
and at any later point in time any third party can query the server to compute a linear combination of data authenticated
by different users and check the correctness of the returned result. Our construction generalizes Boneh et al.’s linearly
homomorphic signature scheme (PKC’09 [7]) to the multi-key setting and relies on basic tools of pairing-based cryptography.
Compared to existing multi-key homomorphic signature schemes, our mklhs is a conceptually simple and elegant direct construction,
which trades-off privacy for efficiency. The simplicity of our approach leads us to a very efficient construction that enjoys
significantly shorter signatures and higher performance than previous proposals. Finally, we implement mklhs using two
different pairing-friendly curves at the 128-bit security level, a Barreto-Lynn-Scott curve and a Barreto-Naehrig curve.
Our benchmarks illustrate interesting performance trade-offs between these parameters, involving the cost of exponentiation and
hashing inpairing groups.
We provide a discussion on such trade-offs that can be useful to other implementers of pairing-based protocols.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>The Rush Dilemma: Attacking and Repairing Smart Contracts on Forking Blockchains</title><link>iSec/event/2019/2019-10-16-css-talk24/</link><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid>iSec/event/2019/2019-10-16-css-talk24/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Daniele Friolo from Sapienza University of Rome, Italy \
&lt;strong>When:&lt;/strong> 15:00 - 16:00 Wednesday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> Room 5128, EDIT building.\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;/p>
&lt;p>We investigate the security of smart contracts within a blockchain that can fork (as Bitcoin and Ethereum). In particular, we focus on multi-party computation (MPC) protocols run on-chain with the aid of smart contracts, and observe that honest players face the following dilemma: Should I rush sending protocol&amp;rsquo;s messages based on the current view of the blockchain, or rather wait that a message is confirmed on the chain before sending the next one?&lt;/p>
&lt;p>To the best of our knowledge, the (implicit) default option used in previous work is the second one and thus known on-chain MPC protocols take long time to be executed on those blockchains with a long confirmation time (e.g., 1 hour per transaction in Bitcoin). While the first option would clearly be preferable for efficiency, we show that this is not necessarily the case for security, as there are natural examples of on-chain MPC protocols that simply become insecure in presence of rushing players.&lt;/p>
&lt;p>Our contributions are twofold:&lt;/p>
&lt;ul>
&lt;li>For the concrete case of fairly tossing multiple coins with penalties, we show that the lottery protocol of Andrychowicz et al. (S&amp;amp;P &amp;lsquo;14) becomes insecure in the presence of rushing players. In addition, we present a new protocol that instead retains security even if the players are rushing.&lt;/li>
&lt;li>We design a compiler that takes any on-chain MPC protocol and transforms it into another one (for the same task) that remains secure even in the presence of rushing players. The only (unavoidable) requirement is that honest players start to be rushing after the first round of the protocol (by all players) has been confirmed on the blockchain.&lt;/li>
&lt;/ul>
&lt;p>Our techniques are inspired by ideas on resettably secure computation (Goyal and Sahai, EUROCRYPT &amp;lsquo;09). We also provide a prototype implementation of our coin tossing protocol using Ethereum smart contracts, and instantiate our generic compiler in a concrete setting, showing that both our constructions yield considerable improvements in terms of efficiency.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>SAID: Reshaping Signal into an Identity-Based Asynchronous Messaging Protocol with Authenticated Ratcheting</title><link>iSec/event/2019/2019-04-24-css-talk23/</link><pubDate>Wed, 24 Apr 2019 00:00:00 +0000</pubDate><guid>iSec/event/2019/2019-04-24-css-talk23/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Elena Pagnin from Aarhus University, Denmark \
&lt;strong>When:&lt;/strong> 10:00 - 11:00 Wednesday {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> Room Analysen, EDIT building.\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
As messaging applications are becoming increasingly popular, it is of utmost importance to analyze their security and mitigate existing weaknesses. This paper focuses on one of the most acclaimed messaging applications: Signal.&lt;/p>
&lt;p>Signal is a protocol that provides end-to-end channel security, forward secrecy, and post-compromise security. These features are achieved thanks to a key-ratcheting mechanism that updates the key material at every message. Due to its high security impact, Signal’s key-ratcheting has recently been formalized, along with an analysis of its security.&lt;/p>
&lt;p>In this paper, we revisit Signal, describing some attacks against the original design and proposing SAID: Signal Authenticated and IDentity-based. As the name indicates, our protocol relies on an identity-based setup, which allows us to dispense with Signal’s centralized server. We use the identity-based long-term secrets to obtain persistent and explicit authentication, such that SAID achieves higher security guarantees than Signal.&lt;/p>
&lt;p>We prove the security of SAID not only in the Authenticated Key Exchange (AKE) model (as done by previous work), but also in the Authenticated and Confidential Channel Establishment (ACCE) model, which we adapted and redefined for SAID and asynchronous messaging protocols in general into a model we call identity-based Multistage Asynchronous Messaging (iMAM). We believe our model to be more faithful in particular to the true security of Signal, whose use of the message keys prevents them from achieving the composable guarantee claimed by previous analysis.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Trusted Execution Environments for Privacy-preserving Cloud Applications</title><link>iSec/event/2018/2018-01-26-css-talk22/</link><pubDate>Fri, 26 Jan 2018 00:00:00 +0000</pubDate><guid>iSec/event/2018/2018-01-26-css-talk22/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Pascal Felber from the University of Neuchâtel, Switzerland \
&lt;strong>When:&lt;/strong> 11:15 - 12:30 Friday{{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> EL42, EDIT building.\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
In this talk, we will give an overview of popular trusted execution environments (TEEs), with special emphasis on Intel&amp;rsquo;s SGX, and we will describe how they can be exploited for implementing privacy-preserving operations in the Cloud that are both secure and efficient. We will discuss their main benefits and limitations, and we will present some of the recent systems that have been developed on top of them.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>CLIO: Cryptographically Secure Information Flow Control on Key-Value Stores</title><link>iSec/event/2017/2017-05-05-css-talk21/</link><pubDate>Fri, 05 May 2017 00:00:00 +0000</pubDate><guid>iSec/event/2017/2017-05-05-css-talk21/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Pablo Buiras, PhD from Chalmers, now PostDoc at Harvard university\
&lt;strong>When:&lt;/strong> 10:30 - 11:30 Friday{{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> room EDIT 3364\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
Cryptography can in principle be used to protect users' data when stored
or transmitted, but in practice is error-prone and can potentially
result in a violation of a user&amp;rsquo;s security concerns.
Information flow control (IFC) systems, on the other hand,
can automatically enforce security policies on data with
policy languages expressive enough to capture many desired
confidentiality and integrity requirements.
In this talk I will present CLIO, an Information flow control (IFC)
system that transparently incorporates cryptography
to enforce confidentiality and integrity policies on untrusted key-value storage.
CLIO insulates developers from explicitly manipulating keys and cryptographic
primitives by leveraging the policy language of the IFC system to
automatically use the appropriate keys and correct cryptographic operations.
Our system relies on a CPA-secure cryptosystem, and we show that CLIO is secure
with a novel proof technique composing cryptographic proof techniques with standard
programming language techniques.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Historical Analyses of the Client-Side Web Security and How to tell people they have an issue</title><link>iSec/event/2017/2017-04-06-css-talk20/</link><pubDate>Thu, 06 Apr 2017 00:00:00 +0000</pubDate><guid>iSec/event/2017/2017-04-06-css-talk20/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> room EDIT 8103\
&lt;strong>When:&lt;/strong> 9:30-10:30{{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> room EDIT 8103 \
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
In this talk, I will present two lines of research I am
currently pursuing. On the one hand, my work focusses on client-side Web
security. To better understand how the eco system evolved, we conducted
a historical study of the last 20 years of the Web using data from the
Internet Archive. Given that the Archive stores all client-side code as
well as relevant header information, this enabled us to analyze trends
over the last years, which allow us to draw conclusions on how future
security mechanisms should be implemented.&lt;/p>
&lt;p>On the other hand, while as a community we have become very good at
discovering vulnerabilities at scale (regardless of Web or network level
flaws), informing the affected parties about the issues has only been
treated as a side note in previous research. To understand how such
notifications can be conducted at scale, we conducted an experiment in
which we notified more than 44,000 vulnerable domains, using different
communication channels. Our work shows that reaching administrators is
the biggest roadblock to a successful notification. In my talk, I will
also discuss some of the technical and human challenges we face when
notifying at scale, moreover highlighting which of these areas require
further research.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Recent work on probabilistic programming languages</title><link>iSec/event/2017/2017-03-06-css-talk19/</link><pubDate>Mon, 06 Mar 2017 00:00:00 +0000</pubDate><guid>iSec/event/2017/2017-03-06-css-talk19/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Daniel Huang \
&lt;strong>When:&lt;/strong> 16.00 {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> 5128 (Grouproom) \
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
In this talk, we will present some of our recent work on probabilistic programming languages. In the first half of the talk, we will describe a semantics for these languages based on Type-2 computable distributions. Such an approach enables us to reason denotationally about probabilistic programs as well as in terms of sampling. In the second half, we will describe a compiler for a simple probabilistic programming language. The compiler uses a sequence of intermediate languages to gradually and successively transform a specification of a probabilistic model into a Markov Chain Monte Carlo inference algorithm for execution on the CPU or GPU.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Privacy and security threat modeling: current research directions</title><link>iSec/event/2017/2017-02-08-css-talk18/</link><pubDate>Wed, 08 Feb 2017 00:00:00 +0000</pubDate><guid>iSec/event/2017/2017-02-08-css-talk18/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Riccardo Scandariato \
&lt;strong>When:&lt;/strong> 11h00 - 11h30 {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> Lindholmen, Jupiter building, 4th floor, room 473\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
Threat analysis is the cornerstone of security-by-design and privacy-by-design approaches for building more secure and privacy-friendly software systems. Threat analysis provides the means to assess a design model (e.g., a software architecture) and identify potential flaws early on in the software development life-cycle. This talk will overview the issues we (empirically) found in state-of-the-practice threat analysis techniques.
Moving forward, the talk will outline our present research directions in the field of threat analysis, with particular focus on a) improving the efficiency of said techniques and b) supporting automated analysis and refactoring.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Security and Privacy on Medical Devices</title><link>iSec/event/2016/2016-10-26-css-talk17/</link><pubDate>Wed, 26 Oct 2016 00:00:00 +0000</pubDate><guid>iSec/event/2016/2016-10-26-css-talk17/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Pablo Picazo\
&lt;strong>When:&lt;/strong> Friday, {{ page.date | date_to_long_string }}\
&lt;strong>Where:&lt;/strong> room 5128\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
The new generation of Implantable Medical Devices (IMDs) is a reality but the security threats mainly linked to the inclusion of wireless connectivity seem to have not received the adequate attention. The security mechanisms supported on-board of these devices must guarantee a balance between the patient safety and the security of the device &amp;ndash; that is, a trade-off between the normal operation mode and the emergency mode. Once introduced the particularities and the security risks of these devices, different security solutions will be revised in the context of identification, key generation, random number generation, etc.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>ZKBoo: Faster Zero-Knowledge for Boolean Circuits</title><link>iSec/event/2016/2016-08-25-css-talk6/</link><pubDate>Thu, 25 Aug 2016 00:00:00 +0000</pubDate><guid>iSec/event/2016/2016-08-25-css-talk6/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> &lt;a href="https://link.com/" target="_blank" rel="noopener">Fname Lname&lt;/a>\
&lt;strong>When:&lt;/strong> Thursday, {{ page.date | date_to_long_string }}, 14:00-15:00\
&lt;strong>Where:&lt;/strong> Room 3364\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
In this talk we describe ZKBoo, a proposal for practically efficient
zero-knowledge arguments especially tailored for Boolean circuits and
report on a proof-of-concept implementation. As an highlight, we can
generate (resp. verify) a non-interactive proof for the SHA-1 circuit in
approximately 13ms (resp. 5ms), with a proof size of 444KB. Our
techniques are based on the “MPC-in-the-head” approach to zero-knowledge
of Ishai et al. (IKOS), which has been successfully used to achieve
significant asymptotic improvements. Our contributions include: 1) A
thorough analysis of the different variants of IKOS, which highlights
their pro and cons for practically relevant soundness parameters; 2) A
generalization and simplification of their approach, which leads to
faster Sigma-protocols (that can be made non-interactive using the
Fiat-Shamir heuristic) for statements of the form “I know x such that y
= f(x)” (where f is a circuit and y a public value); 3) A case study,
where we provide explicit protocols, implementations and benchmarking of
zero-knowledge protocols for the SHA-1 and SHA-256 circuits;&lt;/p>
&lt;p>The paper was published at USENIX Security Symposium 2016 and received
best paper award.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Enhancing the COWL W3C Standard</title><link>iSec/event/2016/2016-06-08-css-talk16/</link><pubDate>Wed, 08 Jun 2016 00:00:00 +0000</pubDate><guid>iSec/event/2016/2016-06-08-css-talk16/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Niklas Andreasson\
&lt;strong>When:&lt;/strong> 10:00, June 8 \
&lt;strong>Where:&lt;/strong> room EDIT 8103\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
Web applications are often composed by resources such as JavaScript
written, and provided, by different parties. This reuse leads to questions concerning security,
and whether one can trust that third-party code will not leak users’ sensitive information.
As it stands today, these concerns are well-founded.&lt;/p>
&lt;p>With the web’s current security primitives there is a trade-off between
developer flexibility and user privacy. If developers choose to include untrusted code then
users’ privacy suffers. On the other hand, if developers abstain from reusing third-party code,
user privacy is favoured, on the cost of developer flexibility. This trade-off can
partly be attributed to the fact that the security primitives are discretionary, where untrusted
code either is granted or denied access to data. After code has been granted access to data
there is no further attempt to verify that the data is used properly.&lt;/p>
&lt;p>In 2014, Stefan et al. proposed a security mechanism which called COWL
(Confinement of Origin Web Labels). COWL is a mandatory access control
which is able to let untrusted code compute on sensitive information, while confining
it. Through this, COWL is able to address some of the shortcomings of the web’s current
security mechanisms, and in the end effectively eliminate the trade-off that exists. Since
the introduction of COWL, it has gone on to become a W3C standard.&lt;/p>
&lt;p>This thesis evaluates the COWL W3C specification by deploying it in
Mozilla Firefox. While COWL aims to mainly address information leaks caused by bugs, we
bring the specification towards addressing malicious code by highlighting two
covert channels: one due to the browser layout engine, and another due to browser
optimizations. Furthermore, we implement two case studies which shows how COWL can be used, and as
part of this, note some practical problems.Through the thesis we managed to make
contributions to the COWL W3C specification.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Selene: Voting with Transparent Verification and Coercion Mitigation</title><link>iSec/event/2016/2016-06-08-css-talk15/</link><pubDate>Wed, 08 Jun 2016 00:00:00 +0000</pubDate><guid>iSec/event/2016/2016-06-08-css-talk15/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Peter Y A Ryan (University of Luxembourg)\
&lt;strong>When:&lt;/strong> 14:30, June 8 \
&lt;strong>Where:&lt;/strong> room EDIT 81033\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
In conventional cryptographic E2E verification schemes, voters are
provided with encrypted ballots that enable them to confirm that their
vote is accurately included in the tally. Technically this is very
appealing, but voters, election officials etc. need to understand some
rather subtle arguments to appreciate the integrity and ballot
secrecy guarantees provided by such mechanisms.&lt;/p>
&lt;p>A simple way to achieve a degree of verifiability and ballot privacy is
to provide each voter with a unique, private tracking number. Votes are
posted on a bulletin board in the clear along with their tracking
number. Thus voters can visit the WBB confirm that there is an entry
with their tracking number showing the correct vote. The beauty of this
approach is its simplicity and understandability. There are, however,
two drawbacks: we must ensure that trackers are unique and a coercer can
demand that the voter reveal her tracking number. It is interesting to
note that the coercer must ask for the tracker before posting. If he
asks after posting the voter has a simple strategy to fool him: just
reads off a tracker number with the coercer&amp;rsquo;s required vote from the WBB.&lt;/p>
&lt;p>In this talk, I describe a scheme that addresses both of these problems.
The main idea is to close off the coercer&amp;rsquo;s window of opportunity by
ensuring that the voters only learn their tracker numbers after votes
have been posted. Notification of the trackers must provide high
assurance but be deniable. The resulting scheme provides
receipt-freeness but also provides a more immediately understandable
form of verifiability: voters can find their vote, in the clear, in the
tally identified by their secret tracker.&lt;/p>
&lt;p>However, there is a sting in the tail: a coerced voter might light on
the coercer&amp;rsquo;s tracker, or the coercer may simply claim that the tracker
is his. I describe some elaborations of the basic scheme to counter this
problem.&lt;/p>
&lt;p>&lt;a href="http://eprint.iacr.org/2015/1105.pdf" target="_blank" rel="noopener">http://eprint.iacr.org/2015/1105.pdf&lt;/a>&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Verification of differential private computationss</title><link>iSec/event/2016/2016-05-31-css-talk14/</link><pubDate>Tue, 31 May 2016 00:00:00 +0000</pubDate><guid>iSec/event/2016/2016-05-31-css-talk14/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Gilles Barthe (IMDEA)\
&lt;strong>When:&lt;/strong> 13:30, May 31 \
&lt;strong>Where:&lt;/strong> room EDIT 8103\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
Differential privacy is a statistical notion of privacy which achieves
compelling trade-offs between input privacy and accuracy (of outputs).
Differential privacy is also an attractive target for verification:
despite their apparent simplicity, recently proposed algorithms have
intricate privacy and accuracy proofs. We present two program logics
for reasoning about privacy and accuracy properties of probabilistic
computations. The accuracy logic captures reasoning about the union
bound, a simple but effective tool from probablility theory, whereas
the privacy logic captures fine-grained reasoning about probabilistic
couplings, a powerful tool for studying Markov chains. We illustrate
the strengths of our program logics with novel and elegant proofs of
challenging examples from differential privacy.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title> Privacy engineering: from the building blocks to the system</title><link>iSec/event/2016/2016-05-29-css-talk11/</link><pubDate>Sun, 29 May 2016 00:00:00 +0000</pubDate><guid>iSec/event/2016/2016-05-29-css-talk11/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Thibaud Antignac\
&lt;strong>When:&lt;/strong> 11:00 am, April 29\
&lt;strong>Where:&lt;/strong> EDIT 8103\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
This talk will be about privacy engineering, a field mainly concerned
with techniques, methods, and tools to systematically take into account
and address privacy issues when building a system. During this journey,
we will explore the difference between security and privacy and see why
the study of privacy in a system requires an interdisciplinary approach.
Finally, we will have a look at the current research challenges needed
to be tackled to be in a situation to deliver more privacy in
information systems.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Architectural requirements for language-level control of external timing channels</title><link>iSec/event/2016/2016-05-27-css-talk10/</link><pubDate>Fri, 27 May 2016 00:00:00 +0000</pubDate><guid>iSec/event/2016/2016-05-27-css-talk10/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Aslan Askarov (Aarhus University)\
&lt;strong>When:&lt;/strong> 14:15, April 27\
&lt;strong>Where:&lt;/strong> room ED\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
A promising new approach to controlling timing channels relies on distinguishing between the direct timing dependencies that are visible at the program control flow level, and the indirect timing dependencies that typically have architectural nature. The approach allows using programming language techniques to mitigate direct dependencies, while delegating the control of the indirect dependencies to the underlying hardware. An essential element in this approach is the so-called semantic interface that stipulates a set of security and functional requirements on hardware in order for the PL-level mitigation to be sound. This talk will present the semantic interface; discuss existing practical realizations from literature, and evaluate security of this approach in a setting of active adversaries that are capable to evict caches.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Frozen Realms: draft standard support for safer JavaScript plugins</title><link>iSec/event/2016/2016-05-27-css-talk13/</link><pubDate>Fri, 27 May 2016 00:00:00 +0000</pubDate><guid>iSec/event/2016/2016-05-27-css-talk13/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Mark S. Miller (Google)\
&lt;strong>When:&lt;/strong> 10:00, May 27 \
&lt;strong>Where:&lt;/strong> room EDIT 3364\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
Support ultra-fine-grain protection domains in JavaScript.
Minimizing standardization, development, explanation, and runtime costs.
Maximizing security, compatibility, simplicity, and expressiveness benefits.
See &lt;a href="https://github.com/FUDCo/proposal-frozen-realms" target="_blank" rel="noopener">https://github.com/FUDCo/proposal-frozen-realms&lt;/a>&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Security of login pages on the Web: who else can know your password?</title><link>iSec/event/2016/2016-05-11-css-talk12/</link><pubDate>Wed, 11 May 2016 00:00:00 +0000</pubDate><guid>iSec/event/2016/2016-05-11-css-talk12/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Steven Van Acker (Chalmers)\
&lt;strong>When:&lt;/strong> 14:15, May 11 \
&lt;strong>Where:&lt;/strong> room ED\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
Most people with an online presence these days, store large amounts of information about their lives in online web services: e-mails, pictures, medical information, &amp;hellip; To prevent unauthorised access to their personal and private information, these web services require users to authenticate and this authentication is typically done using a username and password, transmitted for verification via a login page. These login pages are critical to a user’s security. If an attacker can steal a user&amp;rsquo;s username and password, they can gain access to that user&amp;rsquo;s account easily.&lt;/p>
&lt;p>In this talk we take a look at the state of the art when it comes to security of login pages. We consider several attacker models, ranging from your typical Starbucks network attacker to sophisticated nation-state attackers.&lt;/p>
&lt;p>With these attackers in mind, we look at what the ideal login page looks like, using all security measures currently built into browsers, on top of some common sense.&lt;/p>
&lt;p>Once we know what the ideal login page looks like, we also take a look at real login pages on the Web. We analysed the login pages found on the top 100,000 most popular Internet domains and (responsibly) attacked them using simulated attacker models.&lt;/p>
&lt;p>Beware: This data is part of ongoing research and the results may shock you. You may never wish to use the Web again!&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Program behavior-based fuzzing and vulnerability discovery</title><link>iSec/event/2016/2016-05-06-css-talk9/</link><pubDate>Fri, 06 May 2016 00:00:00 +0000</pubDate><guid>iSec/event/2016/2016-05-06-css-talk9/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Gustavo Grieco (CIFASIS - CONICET and VERIMAG)
&lt;strong>When:&lt;/strong> 11:00, May 6 in
&lt;strong>Where:&lt;/strong> room EDIT 8103
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
Mutational fuzzing is a powerful tool to detect vulnerabilities in software. It requires a initial set of inputs for the program to test. A traditional criteria to select inputs is to maximize code coverage in order to try to use all the instructions at least once. Unfortunately it is still insufficient to deal with real-world code like complex parsers in order to discover vulnerable conditions.&lt;/p>
&lt;p>In this talk we introduce a new approach based on program behaviors, in which traces are extracted and analyzed using Machine Learning to detect similarity between executions. Using this approach, we show how to perform vulnerability detection as well as preliminary results on how to improve seed selection for mutational fuzzing.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title> Two Can Keep a Secret, If One of Them Uses Haskell</title><link>iSec/event/2016/2016-04-15-css-talk8/</link><pubDate>Fri, 15 Apr 2016 00:00:00 +0000</pubDate><guid>iSec/event/2016/2016-04-15-css-talk8/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Alejandro Russo
&lt;strong>When:&lt;/strong> 11:00 am on April 15
&lt;strong>Where:&lt;/strong> Room 3364\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;/p>
&lt;p>For several decades, researchers from different communities have
independently focused on protecting confidentiality of data. Two
distinct technologies have emerged for such purposes: Mandatory
Access Control (MAC) and Information-Flow Control (IFC)—the
former belonging to operating systems (OS) research, while the latter
to the programming languages community. These approaches
restrict how data gets propagated within a system in order to avoid
information leaks. In this scenario, the functional programming language
Haskell plays a unique privileged role: it is able to protect confidentiality via libraries.
This talk presents an (monadic) API which statically protects confidentiality even
in the presence of advanced features like exceptions, concurrency, and mutable data structures.&lt;/p>
&lt;p>This talk is based on the paper &amp;ldquo;Functional Pearl: Two Can Keep a Secret, If One of Them Uses Haskell&amp;rdquo; presented in ICFP 2015.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Recent Breakthroughs in Obfuscation</title><link>iSec/event/2016/2016-04-1-css-talk7/</link><pubDate>Fri, 01 Apr 2016 00:00:00 +0000</pubDate><guid>iSec/event/2016/2016-04-1-css-talk7/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Elena Pagnin
&lt;strong>When:&lt;/strong> Friday April 1, 11:00
&lt;strong>Where:&lt;/strong> Room 8103
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>Abstract:
This talk is supposed to give an overview of the state of the art in the area of Homomorphic Encryption (HE) and Multi-Linear Maps (MLM). The final section of the talk will deal with the definition and application of indistinguishable Obfuscation.
More precisely, I will recall the syntax of FHE schemes and provide a trivial (extremely inefficient) construction of a FHE scheme. I will then cite the most significant papers in the area, highlight the trend and evolution of FHE schemes over the years (since Gentry’s first construction in 2009) and finally conclude with a slide that shows the timing required to perform homomorphic operations on a FHE scheme implemented by Halevi.
The main focus of the talk is on Muliti-Linear Maps (MLM). Roughly speaking, MLMs can be thought of as a FHE scheme in which there is no decryption, but it is possible to check if two (top level) cipher-texts are equal or not. This latter property is called zero testing and it is the main feature, but also weakness, of MLMs. I will present the second MLM candidate, the CLT13, which is based on relatively easy mathematical tools (congruences and Chinese Remainder Theorem), and its cryptanalysis (zeroing attack).
The talk will end with an introduction to obfuscation. &amp;gt;From an abstract point of view, one could think at obfuscation as a MLM without zero testing and in which only a pre-determined sequence of operations is allowed. In practice, an obfuscator is an algorithm that takes as input a program P and outputs another program O(P). such that O(P) and P have equal outputs on equal inputs and O(P) is an intelligible program.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Formal Security Analysis of Mobile and Web Applications</title><link>iSec/event/2016/2016-03-17-css-talk5/</link><pubDate>Thu, 17 Mar 2016 00:00:00 +0000</pubDate><guid>iSec/event/2016/2016-03-17-css-talk5/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> &lt;a href="https://www.sps.cs.uni-saarland.de/maffei/" target="_blank" rel="noopener">Matteo Maffei&lt;/a>\
&lt;strong>When:&lt;/strong> Thursday, {{ page.date | date_to_long_string }}, 13:30-14:30\
&lt;strong>Where:&lt;/strong> Room 3364\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
In this talk, I will present two ongoing projects on the formal
verification of security properties for mobile and web
applications.&lt;/p>
&lt;p>In the first part, I will present HornDroid, a novel technique for the
static analysis of information flow properties in Android
applications. The core idea underlying HornDroid is to use Horn
clauses for soundly abstracting the semantics of Android applications
and to express security properties as a set of proof obligations that
are automatically discharged by SMT solving. This approach makes it
possible to fine-tune the analysis in order to achieve a high degree
of precision while still relying on off-the-shelf verification tools,
thereby automatically leveraging the recent advances in this field. As
a matter of fact, HornDroid outperforms in precision state-of-the-art
Android static analysis tools on benchmarks proposed by the community,
besides being orders of magnitude faster. Moreover, HornDroid is the
first static analysis tool for Android to come with a formal proof of
soundness: besides yielding correctness assurances, this proof allowed
us to identify some critical corner-cases that affect the soundness
guarantees provided by some of the previous static analysis tools for
Android.&lt;/p>
&lt;p>In the second part, I will present Michrome, a security enforcement
tool for web applications based on micro-policies. Micro-policies,
originally proposed to implement hardware-level security monitors,
constitute a flexible and general enforcement technique, based on
assigning security tags to system components and taking security
actions based on dynamic checks over these tags. In this work, we
present the first application of micro-policies to web security, by
proposing a core browser model supporting them and studying its
effectiveness at securing web sessions. In our view, web session
security requirements are expressed in terms of a simple, purely
declarative information flow policy, which is then automatically
translated into a micro-policy implementing it. This leads to a
browser-side enforcement mechanism which is elegant, sound and
flexible, while being accessible to web developers. We show how a
large class of attacks against web sessions can be uniformly and
effectively prevented by the adoption of this approach. Since we
carefully designed micro-policies with ease of deployment in mind, we
are also able to implement our proposal as a Google Chrome extension,
Michrome: our experiments show that Michrome can be easily configured
to enforce strong security policies without breaking the websites
functionality.&lt;/p>
&lt;p>&lt;strong>Biographical Note&lt;/strong>&lt;/p>
&lt;p>Matteo Maffei is professor at Saarland University and CISPA, where he
leads the Secure and Privacy-preserving Systems group. He received his
Ph.D. in Computer Science from the University of Venice in 2006.
Matteo’s research interests are in the area of formal methods for
security analysis, with a focus on cryptographic protocols, mobile
security, and web security, as well as privacy-enhancing technologies,
in particular zero-knowledge proofs, oblivious RAM, and differential
privacy. He was granted the Emmy Noether fellowship from the German
research foundation in 2009, he served in the programme committee of
more than 40 conferences, and he is currently the regular columnist on
security and privacy of the ACM SIGLOG newsletter.ill be summarized and I will discuss future research directions on data anonymization.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Anonymization of sparse multidimensional data</title><link>iSec/event/2016/2016-03-08-css-talk4/</link><pubDate>Tue, 08 Mar 2016 00:00:00 +0000</pubDate><guid>iSec/event/2016/2016-03-08-css-talk4/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> &lt;a href="http://web.imis.athena-innovation.gr/~mter/" target="_blank" rel="noopener">Manolis Terrovitis&lt;/a>\
&lt;strong>When:&lt;/strong> Tuesday, {{ page.date | date_to_long_string }}, 15:00-12:00\
&lt;strong>Where:&lt;/strong> Room 8103\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
Data privacy is of increasing importance as most human activities leave digital traces in some information system. \
In this presentation I will talk about data anonymization and more specifically about protection against identity disclosure in the publication of sparse multidimensional data.
The presentation will explain the notion of km-anonymity and how it is applied to collections of high dimensional data like set-values and tree-structured data.
I will sketch the techniques that anonymize data through generalization, record splitting (disassociation) and algorithms that work on tree-structured data.
The advantages and disadvantages of each approach will be summarized and I will discuss future research directions on data anonymization.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Daniel Hausknecht's Licentiate presentation</title><link>iSec/event/2016/2016-02-29-css-talk3/</link><pubDate>Mon, 29 Feb 2016 00:00:00 +0000</pubDate><guid>iSec/event/2016/2016-02-29-css-talk3/</guid><description>&lt;p>##Talk 1:
&lt;strong>Who:&lt;/strong> William Robertson\
&lt;strong>When:&lt;/strong> Monday, {{ page.date | date_to_long_string }}, 10:00-11:00\
&lt;strong>Where:&lt;/strong> Room 8103\
&lt;strong>Title:&lt;/strong> &lt;em>&lt;strong>on web malware&lt;/strong>&lt;/em> (read abstract and bio below)&lt;/p>
&lt;p>##Talk 2:
&lt;strong>Who:&lt;/strong> Daniel Hausknecht&amp;rsquo;s \
&lt;strong>When:&lt;/strong> Monday, {{ page.date | date_to_long_string }}, 13:15-15:00\
&lt;strong>Where:&lt;/strong> Room EE\
&lt;strong>Title:&lt;/strong> &lt;em>&lt;strong>Licentiate&amp;rsquo;s defence&lt;/strong>&lt;/em> (read abstract below)\
[get the slides here](url for slides)&lt;/p>
&lt;p>&lt;strong>Abstract of Robertson&amp;rsquo;s talk:&lt;/strong>
The modern Web is heavily reliant on JavaScript for implementing
client-side web applications and extending browser functionality. And
yet, despite varied efforts to isolate, tame, or analyze it, JavaScript
continues to enable new attacks against the web platform.&lt;/p>
&lt;p>In this talk, I will present recent work on bypassing browser security
controls via a novel form of code reuse, and discuss a lightweight
static analysis to detect this class of vulnerabilities. Then, I will
present ZigZag, a system for hardening JavaScript-based web applications
against client-side validation vulnerabilities that relies on invariant
detection and efficient instrumentation.&lt;/p>
&lt;p>&lt;strong>Biographical Note&lt;/strong>
William Robertson is an assistant professor of Computer Science at
Northeastern University in Boston, MA, and co-directs the NEU Systems
Security Lab. His research revolves around improving the security of
operating systems, mobile devices, and the web, making use of techniques
such as security by design, program analysis, and anomaly detection.&lt;/p>
&lt;p>&lt;strong>Abstract of Hausknecht&amp;rsquo;s talk:&lt;/strong>&lt;/p></description></item><item><title>Towards more secure and usable text passwords</title><link>iSec/event/2016/2016-01-28-css-talk2/</link><pubDate>Thu, 28 Jan 2016 00:00:00 +0000</pubDate><guid>iSec/event/2016/2016-01-28-css-talk2/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Prof. &lt;a href="http://www.ece.cmu.edu/~lbauer/bio.html" target="_blank" rel="noopener">Lujo Bauer&lt;/a> from Carnegie Mellon University\
&lt;strong>When:&lt;/strong> Thursday, {{ page.date | date_to_long_string }}, 15:00\
&lt;strong>Where:&lt;/strong> Room EA\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>
Many security problems arise at the interface between computer systems and their users. One set of such problems relates to authentication and text-based passwords, which despite numerous shortcomings and attacks remain the dominant authentication method in computer systems.
\
Is pa$$w0rd1 a good password or a bad one? For several years, we&amp;rsquo;ve been studying how to help users create passwords that are hard for attackers to crack, but are still easy for users to remember and use. A key challenge in this work was to develop and validate a methodology for collecting passwords and assessing their strength and usability. I&amp;rsquo;ll discuss our approach, and how we applied it to over 50,000 participants to study the effects of password-composition policies, password-strength meters, and detailed, step-by-step feedback and guidance during the password creation policies.&lt;/p></description></item><item><title>Establishing and Maintaining Root of Trust on Commodity Computer Systems</title><link>iSec/event/2015/2015-11-27-css-talk1/</link><pubDate>Fri, 27 Nov 2015 00:00:00 +0000</pubDate><guid>iSec/event/2015/2015-11-27-css-talk1/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> &lt;a href="http://users.ece.cmu.edu/~virgil/" target="_blank" rel="noopener">Virgil Gligor&lt;/a> CMU\
&lt;strong>When:&lt;/strong> Friday, {{ page.date | date_to_long_string }}, 11:00-12:00\
&lt;strong>Where:&lt;/strong> Room 8103\
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\
Suppose that a trustworthy program must be booted on a commodity system that may contain persistent malware. For example, a formally verified micro-kernel, micro-hypervisor, or a subsystem obtained from a trustworthy provider must be booted on a computer system that runs Windows, Linux, or Android applications. Establishing root of trust assures the user that either the system is in a malware-free state in which the trustworthy-program boot takes place or the presence of malware is discovered, with high probability. Obtaining such assurance is challenging because malware can survive in system state across repeated secure- and trusted-boot operations. These operations do not always have malware-unmediated access to device memories; e.g., memories of bring-your-own devices (e.g., keyboards, consoles, printers, routers), and sometimes even disk controllers. They certainly have no unmediated access to all non-volatile memories of interconnected components of a personal system; e.g., components of home systems, autos. To date, concrete assurance for root-of-trust establishment has not been obtained on commodity systems that scale to large configurations.
\
Establishing root of trust makes all persistent malware ephemeral and forces the adversary to repeat the malware-insertion attack, perhaps at some added cost. Nevertheless, some malware-controlled software can always be assumed to exist in commodity operating systems and applications. The inherent size and complexity of their operating systems and applications (aka the “giants”) render them vulnerable to successful adversary attacks. In contrast, small and simple software components with rather limited function and high-assurance layered security properties (aka the “wimps”) can be resistant to adversary attacks.
Maintaining root of trust assures a user that a commodity computer’s wimps are isolated from, and safely co-exist with, adversary-controlled giants. To survive, secure wimps must use services of, or compose with, insecure giants. This appears to be “paradoxical:” wimps can counter all adversary attacks but survive only if they use giants’ adversary-controlled services from which they have to defend themselves.
\
I this seminar, I will illustrate the challenges of root-of-trust establishment via “verifiable boot” operations that do not require secrets, TPMs, or adversary bounds. Then, I will present a method to define a wimp’s adversary accurately and completely using a structure found in cryptographic protocols. A consequence of such definitions is the ability to produce partial orders on adversary attacks. Finally, I will present secure wimp composition with giants, via two examples of experimental systems (i.e., on-demand isolated I/O channels and a trusted display service) designed and implemented at CMU CyLab.&lt;/p>
&lt;p>&lt;strong>Biographical Note&lt;/strong>
Virgil D. Gligor received his B.Sc., M.Sc., and Ph.D. degrees from the University of California at Berkeley. He taught at the University of Maryland between 1976 and 2007, and is currently a Professor of ECE at Carnegie Mellon University. Between 2007 and 2015 he was the co-Director of CyLab. Over the past forty years, his research interests ranged from access control mechanisms, penetration analysis, and denial-of-service protection, to cryptographic protocols and applied cryptography. Gligor was an editorial board member of several ACM and IEEE journals and the Editor in Chief of the IEEE Transactions on Dependable and Secure Computing. He received the 2006 National Information Systems Security Award jointly given by NIST and NSA, the 2011 Outstanding Innovation Award of the ACM SIG on Security Audit and Control, and the 2013 Technical Achievement Award of the IEEE Computer Society.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item></channel></rss>