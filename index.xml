<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Chalmers Security &amp; Privacy Lab</title><link>https://www.cse.chalmers.se/research/group/security/</link><atom:link href="https://www.cse.chalmers.se/research/group/security/index.xml" rel="self" type="application/rss+xml"/><description>Chalmers Security &amp; Privacy Lab</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 13 Mar 2024 13:30:00 +0000</lastBuildDate><image><url>https://www.cse.chalmers.se/research/group/security/media/icon_huf405b5a3d64669240eafa59ffeef17e8_561926_512x512_fill_lanczos_center_2.png</url><title>Chalmers Security &amp; Privacy Lab</title><link>https://www.cse.chalmers.se/research/group/security/</link></image><item><title>Experimental Analyses of the Physical Surveillance Risks in Client-side Content Scanning</title><link>https://www.cse.chalmers.se/research/group/security/event/2023/2024-03-13-earlance/</link><pubDate>Wed, 13 Mar 2024 13:30:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2023/2024-03-13-earlance/</guid><description>&lt;p>Earlence Fernandes is an assistant professor of computer science at UC San Diego. His research focuses on computer security for emerging technologies. He has received two best paper awards, the NSF CAREER award, and research awards from Meta and Amazon. He hacked a Stop sign once, and it is now in a museum.&lt;/p>
&lt;p>&lt;a href="https://www.earlence.com/" target="_blank" rel="noopener">Earlence Fernandes&amp;rsquo;s webpage&lt;/a>&lt;/p></description></item><item><title>Beyond Notice and Consent: Towards More Usable Privacy Under European Data Protection and Platform Regulations</title><link>https://www.cse.chalmers.se/research/group/security/event/2023/2023-12-14-christine/</link><pubDate>Thu, 14 Dec 2023 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2023/2023-12-14-christine/</guid><description>&lt;p>Christine Utz (she/her) is a postdoctoral researcher at the CISPA Helmholtz Center for Information Security in Saarbrücken, Germany. She holds bachelor&amp;rsquo;s and master&amp;rsquo;s degrees in information security and a PhD in computer science from Ruhr University Bochum, as well as a law degree from the University of Bayreuth. Her doctoral research concerned effects of the GDPR on third-party web tracking and was conducted within the framework of an interdisciplinary graduate school, SecHuman - Security for People in Cyberspace. She combines online measurements with methods from human-computer interaction to foster people&amp;rsquo;s awareness and agency regarding the processing of their personal data. Her work was published at leading venues for security &amp;amp; privacy and human-computer interaction and was repeatedly featured at the FTC PrivacyCon in Washington, DC.&lt;/p>
&lt;p>&lt;a href="https://cispa.de/en/people/c01chut" target="_blank" rel="noopener">Christine Utz&amp;rsquo;s webpage&lt;/a>&lt;/p></description></item><item><title>The ambivalent role of deep learning in cybersecurity: insights from traffic analysis attacks and defenses</title><link>https://www.cse.chalmers.se/research/group/security/event/2023/2023-12-01-vera/</link><pubDate>Fri, 01 Dec 2023 14:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2023/2023-12-01-vera/</guid><description>&lt;p>Vera Rimmer is a post-doctoral researcher at the DistriNet lab in KU Leuven, Belgium, where she has recently completed her PhD under the supervision of Prof. Wouter Joosen and Dr. Davy Preuveneers. She studies cybersecurity and privacy-enhancing technologies; data analytics in cybersecurity and privacy; applied machine learning and deep learning; privacy and trustworthiness of applied data-driven AI. Her published research revolves around exploring deep learning as a threat against anonymous communication, and various aspects of AI-enabled network intrusion detection and authentication.&lt;/p>
&lt;p>&lt;a href="https://distrinet.cs.kuleuven.be/people/VeraRimmer" target="_blank" rel="noopener">Vera Rimmer&amp;rsquo;s webpage&lt;/a>&lt;/p></description></item><item><title>Hardware-software co-designs for microarchitectural security beyond constant-time programming</title><link>https://www.cse.chalmers.se/research/group/security/event/2023/2023-11-20-lesly-ann/</link><pubDate>Mon, 20 Nov 2023 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2023/2023-11-20-lesly-ann/</guid><description>&lt;p>Lesly-Ann Daniel is a post-doctoral researcher at the DistriNet lab in KU Leuven, Belgium, working with Frank Piessens working on hardware software co-designs for security. She completed her PhD in 2021 at CEA List, France, under the supervision of Tamara Rezk and Sébastien Bardin. She is generally interested in the application of formal methods for microarchitectural security, and more particularly in binary analysis, secure compilation, design of hardware defenses, and hardware verification.&lt;/p>
&lt;p>&lt;a href="https://leslyann-daniel.fr/" target="_blank" rel="noopener">Lesly-Ann Daniel&amp;rsquo;s webpage&lt;/a>&lt;/p></description></item><item><title>Integrating Side Channel Security into the High Level Synthesis based Design Flow</title><link>https://www.cse.chalmers.se/research/group/security/event/2023/2023-11-13-yuki/</link><pubDate>Mon, 13 Nov 2023 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2023/2023-11-13-yuki/</guid><description>&lt;p>Yuko Hara-Azumi received her Ph.D. degree in Information Science from Nagoya University, Japan, in 2010. She was a JSPS postdoctoral research fellow from 2010 to 2012, during which she was also a visiting scholar at University of California, Irvine, USA and Karlsruhe Institute of Technology, Germany. In 2012, she joined Nara Institute of Science and Technology, as an assistant professor. Since 2014, she has been with School of Engineering, Tokyo Institute of Technology, where she is currently an associate professor. She was a visiting scholar at Katholieke Universiteit Leuven, Belgium in 2023. Her research interests include system-level design automation, microprocessor architecture, and hardware/software co-design for embedded/IoT systems.&lt;/p>
&lt;p>&lt;a href="https://sites.google.com/site/yukoharaazumi/home" target="_blank" rel="noopener">Yuko Hara-Azumi&amp;rsquo;s webpage&lt;/a>&lt;/p></description></item><item><title>Provably Sound Static Analysis for Ethereum Smart Contracts</title><link>https://www.cse.chalmers.se/research/group/security/event/2023/2023-10-19-clara/</link><pubDate>Thu, 19 Oct 2023 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2023/2023-10-19-clara/</guid><description>&lt;p>Clara Schneidewind is a research group leader at the Max Planck Institute for Security and Privacy (MPI-SP) in Bochum. In her research, she is interested in improving the security and scalability of blockchain-based applications using techniques from formal methods and applied cryptography.&lt;/p>
&lt;p>&lt;a href="https://www.mpi-sp.org/schneidewind" target="_blank" rel="noopener">Clara Schneidewind&amp;rsquo;s webpage&lt;/a>&lt;/p></description></item><item><title>Mutual Contact Discovery</title><link>https://www.cse.chalmers.se/research/group/security/event/2023/2023-10-16-jaap-henk/</link><pubDate>Mon, 16 Oct 2023 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2023/2023-10-16-jaap-henk/</guid><description>&lt;p>Jaap-Henk Hoepman is guest professor at the PRISEC - Privacy And Security group of Karlstad University, Sweden.&lt;/p>
&lt;p>He is also an associate professor of privacy enhancing protocols and privacy by design in the Digital Security group at the Institute for Computing and Information Sciences of the Radboud University Nijmegen, principal scientist of the Privacy &amp;amp; Identity Lab, and member of iHub, Radboud University’s interdisciplinary research hub on Digitalization and Society.&lt;/p>
&lt;p>Moreover he is an associate professor in the IT Law section of the Transboundary Legal Studies department of the Faculty of Law of the University of Groningen.&lt;/p>
&lt;p>His main research interest are privacy by design, privacy friendly protocols and identity management.&lt;/p>
&lt;p>He also writes a lot about the societal impact of new technologies.&lt;/p>
&lt;p>&lt;a href="https://www.cs.ru.nl/J.H.Hoepman/" target="_blank" rel="noopener">Jaap-Henk Hoepman&amp;rsquo;s webpage&lt;/a>&lt;/p></description></item><item><title>Research challenges for the Tor anonymous communication system</title><link>https://www.cse.chalmers.se/research/group/security/event/2023/2023-08-22-steven/</link><pubDate>Tue, 22 Aug 2023 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2023/2023-08-22-steven/</guid><description>&lt;p>Professor Steven Murdoch is the head of University College London&amp;rsquo;s Information Security Research Group. His research interests include payment systems and privacy-enhancing technologies, particularly anonymous communication systems. He was the creator of the Tor Browser and continues to be a member of the Tor Project. He is a Fellow of the IET and BCS and a director of the Open Rights Group.&lt;/p>
&lt;p>&lt;a href="https://murdoch.is/" target="_blank" rel="noopener">Steven Murdoch&amp;rsquo;s webpage&lt;/a>&lt;/p></description></item><item><title>Building a Secure Foundation</title><link>https://www.cse.chalmers.se/research/group/security/event/2023/2023-05-03-michael/</link><pubDate>Wed, 03 May 2023 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2023/2023-05-03-michael/</guid><description>&lt;p>Michael Weissbacher is a Staff Security Engineer at Block where he develops infrastructure software that makes the business operate more securely. His primary area is providing identity to workloads in the cloud. Michael has a PhD from Northeastern University where he was working at the Secure Systems Lab. His main area of research was web security, he also worked on fuzzing for algorithmic slowdowns and integrating humans with automated program exploitation. His work was published in venues such as USENIX Security, ACM CCS, NDSS, and others. He has presented work on detecting privacy invasions of browser extensions at the FTC, which has been covered by various news outlets, such as Le Figaro and Heise. Michael’s recent industry work has been presented at Black Hat USA in 2021.&lt;/p>
&lt;p>&lt;a href="https://mweissbacher.com/" target="_blank" rel="noopener">Michael Weissbacher&amp;rsquo;s webpage&lt;/a>&lt;/p></description></item><item><title>Security Properties through the Lens of Modal Logic</title><link>https://www.cse.chalmers.se/research/group/security/event/2023/2023-03-30-matvey/</link><pubDate>Thu, 30 Mar 2023 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2023/2023-03-30-matvey/</guid><description>&lt;p>Matvey Soloviev is a postdoc at KTH working under Musard Balliu. Previously, he obtained a Ph.D. at Cornell University under the supervision of Joseph Y. Halpern. The focus of his research is in developing formal approaches to program security by borrowing insights from fields such as logic, analytic philosophy and game theory.&lt;/p>
&lt;p>&lt;a href="https://www.kth.se/profile/matvey?l=en" target="_blank" rel="noopener">Matvey Soloviev&amp;rsquo;s webpage&lt;/a>&lt;/p></description></item><item><title>Computer-Aided Formal Security Analysis of the Web Platform</title><link>https://www.cse.chalmers.se/research/group/security/event/2023/2023-03-23-matteo/</link><pubDate>Thu, 23 Mar 2023 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2023/2023-03-23-matteo/</guid><description>&lt;p>Matteo Maffei is professor for Security at TU Wien since 2017. Previously, he was professor at Saarland University - CISPA. He obtained his Ph.D. in Computer Science at the Ca’ Foscari University of Venice in 2006.&lt;/p>
&lt;p>Matteo Maffei received an ERC Consolidator Grant in 2018 and a DFG Emmy Noether Fellowship in 2009. He is director of the TU Wien doctoral school SecInt, local leader of the Christian Doppler Lab Blockchain Technologies for the Internet of Things, and director of the FWF special research program SPyCoDe.&lt;/p>
&lt;p>His current research interests focus on formal methods for security and privacy, web security, and blockchain technologies.&lt;/p>
&lt;p>&lt;a href="https://informatics.tuwien.ac.at/people/matteo-maffei" target="_blank" rel="noopener">Matteo Maffei&amp;rsquo;s webpage&lt;/a>&lt;/p></description></item><item><title>Mind the gap: the challenges of taking differential privacy out of the lab and into the field</title><link>https://www.cse.chalmers.se/research/group/security/event/2023/2023-03-23-michael/</link><pubDate>Thu, 23 Mar 2023 10:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2023/2023-03-23-michael/</guid><description>&lt;p>Michael Hay is the Founder/CTO of Tumult Labs and an Associate Professor of Computer Science at Colgate University. He was previously a Research Data Scientist at the US Census Bureau and a Computing Innovation Fellow at Cornell University. He holds a Ph.D. from the University of Massachusetts Amherst and a bachelor&amp;rsquo;s degree from Dartmouth College.&lt;/p>
&lt;p>&lt;a href="https://cs.colgate.edu/~mhay/index.html" target="_blank" rel="noopener">Michael Hay&amp;rsquo;s webpage&lt;/a>&lt;/p></description></item><item><title>How have threat models changed since 2018 and how hardware security can help handle the new threats?</title><link>https://www.cse.chalmers.se/research/group/security/event/2023/2023-03-16-tamara/</link><pubDate>Thu, 16 Mar 2023 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2023/2023-03-16-tamara/</guid><description>&lt;p>&lt;a href="https://www-sop.inria.fr/lemme/Tamara.Rezk/" target="_blank" rel="noopener">Tamara Rezk&lt;/a> is a research director at Inria, Sophia Antipolis, France. Her main research interests are in the field of system security. She currently focuses her research on program analyses and principled methods to deal with transient execution attacks and JavaScript security.
She has supervised Ph.D. students on topics such as static and dynamic security analyses, web security, formal methods for security, secure compilation, and provable cryptography.&lt;/p></description></item><item><title>Categorical Composable Cryptography</title><link>https://www.cse.chalmers.se/research/group/security/event/2023/2023-03-13-martti/</link><pubDate>Mon, 13 Mar 2023 15:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2023/2023-03-13-martti/</guid><description>&lt;p>&lt;a href="https://mysite.science.uottawa.ca/mkarvone/" target="_blank" rel="noopener">Martti Karvonen&lt;/a> is a postdoc at the University of Ottawa. His research interests include category theory and its applications to fields such as cryptography and quantum computing.&lt;/p></description></item><item><title>Composable Non-interactive Zero-knowledge Proofs in the Random Oracle Model</title><link>https://www.cse.chalmers.se/research/group/security/event/2023/2023-03-09-yash/</link><pubDate>Thu, 09 Mar 2023 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2023/2023-03-09-yash/</guid><description>&lt;p>&lt;a href="https://www.ykondi.net/" target="_blank" rel="noopener">Yashvanth Kondi&lt;/a> is a postdoc at Aarhus University. His research interests include the theoretical and practical aspects of Multiparty Computation and Zero-knowledge proofs.&lt;/p></description></item><item><title>FrodoPIR: Simple, Scalable, Single-Server Private Information Retrieval</title><link>https://www.cse.chalmers.se/research/group/security/event/2023/2023-03-02-sofia/</link><pubDate>Thu, 02 Mar 2023 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2023/2023-03-02-sofia/</guid><description>&lt;p>&lt;a href="https://sofiaceli.com/" target="_blank" rel="noopener">Sofía Celi&lt;/a> is a cryptography researcher at Brave. She is the co-chair of the human rights and protocols considerations working group at IRTF, of the Post-Quantum Use In Protocols working group at IETF, and of the anti-fraud community group at W3C. She studied classical music and literature, but currently researches about security, cryptography and privacy on the Internet.&lt;/p></description></item><item><title>Privacy with Good Taste: A Case Study in Quantifying Privacy Risks in Genetic Scores</title><link>https://www.cse.chalmers.se/research/group/security/event/2023/2023-02-09-raul/</link><pubDate>Thu, 09 Feb 2023 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2023/2023-02-09-raul/</guid><description>&lt;p>&lt;a href="http://raulpardo.net/" target="_blank" rel="noopener">Raúl Pardo&lt;/a> is an assistant professor in computer science at the IT University of Copenhagen. In the past, he was a postdoc in the SQUARE group at the IT University of Copenhagen hosted by Andrzej Wąsowski. Previously, he was a postdoc in the Privatics team at Inria hosted by Daniel Le Métayer. He has a PhD degree in computer science from Chalmers University of Technology.&lt;/p></description></item><item><title>Publicly Auditable Privacy Revocation</title><link>https://www.cse.chalmers.se/research/group/security/event/2023/2023-01-19-joakim/</link><pubDate>Thu, 19 Jan 2023 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2023/2023-01-19-joakim/</guid><description>&lt;p>Joakim Brorsson is a PhD student at Lund University, co-supervised by Elena Pagnin at Chalmers University. His research interests lie in security and cryptographic methods to reduce trust in third parties.&lt;/p></description></item><item><title>PrePaMS: Privacy-Preserving Participant Management for Studies with Rewards</title><link>https://www.cse.chalmers.se/research/group/security/event/2022/2022-12-15-felix/</link><pubDate>Thu, 15 Dec 2022 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2022/2022-12-15-felix/</guid><description>&lt;p>&lt;a href="https://felix.nlogn.org/" target="_blank" rel="noopener">Felix Engelmann&lt;/a> a Postdoc at &lt;a href="https://pure.itu.dk/portal/en/persons/felix-theodor-engelmann" target="_blank" rel="noopener">ITU Copenhagen&lt;/a>.
His research focuses on non-interactive zero-knowledge proofs, anonymity and confidentiality, and token transaction systems.&lt;/p></description></item><item><title>Social psychology and its potential effect on security when developing software systems</title><link>https://www.cse.chalmers.se/research/group/security/event/2022/2022-12-08-lucas/</link><pubDate>Thu, 08 Dec 2022 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2022/2022-12-08-lucas/</guid><description>&lt;p>&lt;a href="https://www.cse.chalmers.se/~lucasg/" target="_blank" rel="noopener">Lucas Gren&lt;/a> is a Senior Lecturer in Software Engineering with a cross-disciplinary background. He has a PhD in Software Engineering and Master&amp;rsquo;s Degrees in Psychology and Business Administration Management. Lucas has three years of experience leading the agile transformation at Volvo Cars focusing on the group dynamics of agile teams, which also was the topic of his PhD thesis. Today Lucas does research within the interdisciplinary field of combining Organizational Psychology with Software Engineering Processes.&lt;/p></description></item><item><title>Transport-Level Privacy for Instant Messaging</title><link>https://www.cse.chalmers.se/research/group/security/event/2022/2022-12-01-boel/</link><pubDate>Thu, 01 Dec 2022 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2022/2022-12-01-boel/</guid><description>&lt;p>&lt;a href="http://boelnelson.com/" target="_blank" rel="noopener">Boel Nelson&lt;/a> is a postdoc in the Algorithms and
Complexity section at University of Copenhagen, and a member of Basic
Algorithms Research Copenhagen (BARC). She is an upcoming Marie
Skłodowska-Curie postdoctoral fellow—starting her project on Provable Privacy
for Metadata (ProPriM) in August 2023 at Aarhus University. Her research
interests include data privacy, detection and mitigation of side-channels,
and privacy enhancing technologies.&lt;/p>
&lt;p>Prior to joining UCPH/BARC, Boel worked as a postdoc in the Logic and
Semantics group at Aarhus University, where she conducted research on
anonymous communication. Boel earned her PhD from Chalmers University of
Technology in 2021.&lt;/p></description></item><item><title>Applying Cryptography’s Real/Ideal Paradigm to PL Security</title><link>https://www.cse.chalmers.se/research/group/security/event/2022/2022-11-23-alley/</link><pubDate>Wed, 23 Nov 2022 10:30:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2022/2022-11-23-alley/</guid><description>&lt;p>&lt;a href="https://alleystoughton.us/" target="_blank" rel="noopener">Alley Stoughton&lt;/a> is a research professor at Boston University. She earned her doctorate in computer science from University of Edinburgh in 1987, and has a background in programming language semantics and functional programming. But in recent years her focus has been on security, mainly using the EasyCrypt proof assistant to prove the security of cryptographic protocols.&lt;/p></description></item><item><title>From GDPR to Information Flow Semantics</title><link>https://www.cse.chalmers.se/research/group/security/event/2022/2022-11-17-eliza/</link><pubDate>Thu, 17 Nov 2022 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2022/2022-11-17-eliza/</guid><description>&lt;p>&lt;a href="https://ekozyri.com/" target="_blank" rel="noopener">Elisavet Kozyri&lt;/a> is an associate professor of Computer Science at UiT The Arctic University of Norway. Her research area is Computer Security, and more specifically Information Flow Control. She received her Ph.D. in Computer Science from Cornell University under the supervision of Prof. Fred B. Schneider. After that, she was a postdoctoral fellow in Computer Science at Harvard University working with Prof. Stephen Chong. Elisavet completed her undergraduate studies in ECE at the National Technical University of Athens, Greece.&lt;/p></description></item><item><title>Keeping Humans on the Loop when Designing and Operating Autonomous Systems</title><link>https://www.cse.chalmers.se/research/group/security/event/2022/2022-10-20-rebekka/</link><pubDate>Thu, 20 Oct 2022 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2022/2022-10-20-rebekka/</guid><description>&lt;p>&lt;a href="https://rebekkaa.github.io/" target="_blank" rel="noopener">Rebekka Wohlrab&lt;/a> is an assistant professor in Software Engineering at &lt;a href="https://www.chalmers.se/" target="_blank" rel="noopener">Chalmers University of Technology&lt;/a> in Gothenburg, Sweden.
She is doing research in the areas of self-adaptive systems, software architecture, and requirements engineering.&lt;/p></description></item><item><title>Victor Morel's introductory talk - Design and analysis of technical systems for humans</title><link>https://www.cse.chalmers.se/research/group/security/event/2022/2022-10-06-victor/</link><pubDate>Thu, 06 Oct 2022 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2022/2022-10-06-victor/</guid><description>&lt;p>&lt;a href="https://victor-morel.net/" target="_blank" rel="noopener">Victor Morel&lt;/a> holds a PhD in computer science from Inria - Privatics.&lt;/p>
&lt;p>His research interests include privacy and data protection, networks security, usability, applied cryptography, and ethics of technology in a broad manner.&lt;/p></description></item><item><title>Practical problems in enforcing Data Protection by Design &amp; by Default - the perspective of a Data Protection Authority</title><link>https://www.cse.chalmers.se/research/group/security/event/2022/2022-09-23-marit/</link><pubDate>Fri, 23 Sep 2022 13:30:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2022/2022-09-23-marit/</guid><description>&lt;p>Since 2015 &lt;a href="https://www.hansen-kronshagen.de/marit/en/" target="_blank" rel="noopener">Marit Hansen&lt;/a> has been the State Data Protection Commissioner of Land Schleswig-Holstein and Chief of Unabhängiges Landeszentrum für Datenschutz (ULD). Before being appointed Data Protection Commissioner, she had been Deputy Commissioner for seven years. Since her diploma in computer science in 1995 Marit has been working on privacy and security aspects. Her focus is on “data protection by design” and “data protection by default” from both the technical and the legal perspectives. She often gives talks and has been lecturing at various universities and academies and has contributed to several EU and national research projects. Marit was member of the Data Ethics Commission of the German Government. Her contribution to education and research on privacy-enhancing technologies has awarded her an honorary doctorate from Karlstad University, Sweden.&lt;/p></description></item><item><title>CatNap: a Protocol for Server-aided Proximity Testing</title><link>https://www.cse.chalmers.se/research/group/security/event/2022/2022-06-20-ivan/</link><pubDate>Mon, 20 Jun 2022 10:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2022/2022-06-20-ivan/</guid><description>&lt;p>&lt;a href="https://www.chalmers.se/sv/personal/Sidor/ivanol.aspx" target="_blank" rel="noopener">Ivan Oleynikov&lt;/a> is a
PhD student at Chalmers. He&amp;rsquo;s working on solving Location Privacy
problems using Cryptographic tools, together with Elena Pagnin and
Andrei Sabelfeld. Before Chalmers he studied Complexity Theory and got
his Master&amp;rsquo;s degree at Academic University in St. Petersburg, Russia.&lt;/p>
&lt;p>Paper link: &lt;a href="https://www.cse.chalmers.se/research/group/security/catnap/">https://www.cse.chalmers.se/research/group/security/catnap/&lt;/a>&lt;/p></description></item><item><title>TypeScript Analysis in Prime Video</title><link>https://www.cse.chalmers.se/research/group/security/event/2022/2022-05-20-daniel/</link><pubDate>Fri, 20 May 2022 15:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2022/2022-05-20-daniel/</guid><description>&lt;p>&lt;a href="https://schoepe.org/~daniel/" target="_blank" rel="noopener">Daniel Schoepe&lt;/a> is an Applied
Scientist working in the Amazon Prime Video Automated Reasoning
team. His work is focused on proving properties of TypeScript programs
using an in-house abstract interpretation framework written in
Scala 3. Daniel has a PhD in Computer Science from Chalmers University
of Technology, Sweden, where he worked on language-based security and
information-flow control.&lt;/p></description></item><item><title>Adventures in program synthesis</title><link>https://www.cse.chalmers.se/research/group/security/event/2022/2022-05-20-koen/</link><pubDate>Fri, 20 May 2022 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2022/2022-05-20-koen/</guid><description>&lt;p>Speaker website: &lt;a href="https://www.cse.chalmers.se/~koen/">https://www.cse.chalmers.se/~koen/&lt;/a>&lt;/p></description></item><item><title>Towards usable differentially private analyses — Exploring suitable metaphors for lay users</title><link>https://www.cse.chalmers.se/research/group/security/event/2022/2022-03-11-simone/</link><pubDate>Fri, 11 Mar 2022 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2022/2022-03-11-simone/</guid><description>&lt;p>&lt;a href="https://simone.hotell.kau.se/" target="_blank" rel="noopener">Simone Fischer-Hübner&lt;/a> received the
Diploma degree in computer science (law), in 1988, and the Ph.D. and
Habilitation degrees in computer science from the University of
Hamburg, Germany, in 1992 and 1999, respectively. She has been a Full
Professor with &lt;a href="https://www.kau.se/en" target="_blank" rel="noopener">Karlstad University&lt;/a>, Sweden,
since 2000, where she is currently the Head of the Privacy and
Security Research Group. She is also a Scientific Coordinator with the
EU H2020 Marie Skłodowska-Curie ITN Privacy &amp;amp; Us. She has contributed
as a Partner with the CyberSec4Europe, PAPAYA, CREDENTIAL,
PRISMACLOUD, A4Cloud, SmartSociety, PrimeLife, PRIME, FIDIS, and Bugyo
EU projects. Her research interests include cyber security,
privacy-enhancing technologies, and usable privacy and security. She
is a Swedish IFIP TC 11 Representative and a member of the Advisory
Board Swedish Civil Contingency Agency&amp;rsquo;s Cyber Security Council. She
serves as the Vice Chair for the IEEE Sweden Computer/Software
Engineering Chapter.&lt;/p>
&lt;p>&lt;a href="https://www.kau.se/en/researchers/farzaneh-karegar" target="_blank" rel="noopener">Farzaneh Karegar&lt;/a>
has a Bachelor&amp;rsquo;s degree from &lt;a href="https://ut.ac.ir/en" target="_blank" rel="noopener">University of Tehran
(UT)&lt;/a>, a Master&amp;rsquo;s degree in Computer Engineering
from &lt;a href="https://en.sbu.ac.ir/" target="_blank" rel="noopener">Shahid Beheshti University (SBU)&lt;/a> and a
PhD from &lt;a href="https://www.kau.se/en" target="_blank" rel="noopener">Karlstad University&lt;/a>. Currently, she
is working on algorithmic transparency and usable transparency of
privacy-preserving data analytics with a focus on usable differential
privacy.&lt;/p></description></item><item><title>LogPicker: Strengthening Certificate Transparency Against Covert Adversaries</title><link>https://www.cse.chalmers.se/research/group/security/event/2022/2022-03-04-alexandra/</link><pubDate>Fri, 04 Mar 2022 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2022/2022-03-04-alexandra/</guid><description>&lt;p>&lt;a href="https://www.tu-braunschweig.de/en/ias/staff/alexandra-dirksen" target="_blank" rel="noopener">Alexandra Dirksen&lt;/a>
is a PhD Candidate at &lt;a href="https://www.tu-braunschweig.de/en/" target="_blank" rel="noopener">TU Braunschweig&lt;/a>
and is currently working in the field of Web Security &amp;amp; Privacy, Web
PKI and Large Scale Adversaries. Her further interests are different
topics of Applied Cryptography and Ethics in Computer Science. She is
currently part of the &lt;a href="https://kiwi-project.org/" target="_blank" rel="noopener">KIWI Project&lt;/a>, where
she works on mechanisms to detect security issues in OAuth protocol
flows at runtime.&lt;/p></description></item><item><title>End-to-End Security for Evolved Computer Systems</title><link>https://www.cse.chalmers.se/research/group/security/event/2022/2022-02-25-earlence/</link><pubDate>Fri, 25 Feb 2022 14:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2022/2022-02-25-earlence/</guid><description>&lt;p>&lt;a href="http://www.earlence.com/" target="_blank" rel="noopener">Earlence Fernandes&lt;/a> is an assistant
professor of computer science at the University of
Wisconsin-Madison. His goal is to enable society to gain the benefits
of evolved computer systems without the security and privacy
risks. Earlence is a recipient of multiple best paper awards, a
Facebook research award and the NSF CAREER award. He once hacked a
Stop sign, and it is now in a museum.&lt;/p></description></item><item><title>With a Little Help from My Friends: Transport Deniability for Instant Messaging</title><link>https://www.cse.chalmers.se/research/group/security/event/2022/2022-02-11-boel/</link><pubDate>Fri, 11 Feb 2022 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2022/2022-02-11-boel/</guid><description>&lt;p>Boel Nelson is a postdoc at Aarhus University. Her research interests include privacy enhancing technologies, data privacy, and real-world applications of security and privacy techniques.
Boel graduated with a PhD (topic: differential privacy) from Chalmers University of Technology in 2021. She holds a MSc in Computer Science and Engineering, and a BSc in Software Engineering, also from Chalmers University of Technology.&lt;/p></description></item><item><title>On Progressive and Efficient Verification of Digital Signatures</title><link>https://www.cse.chalmers.se/research/group/security/event/2022/2022-02-04-elena/</link><pubDate>Fri, 04 Feb 2022 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2022/2022-02-04-elena/</guid><description>&lt;p>&lt;a href="https://epagnin.github.io" target="_blank" rel="noopener">Elena Pagnin&lt;/a> is currently an assistant professor at Lund University (Sweden). Here she is an active member of the CRYSPY lab (CRYptography Security and PrivacY). Her research is focused on cryptography and security, with a special interest for homomorphic cryptosystems, data authentication and user privacy. Prior to joining Lund University, Elena has been a post doctoral researcher in the crypto group at Aarhus University (Denmark). Elena completed her PhD at Chalmers (Göteborg, Sweden) in 2019. Her motto is: det är lätt att vara efterklok (it’s easy to be wise in hindsight).&lt;/p></description></item><item><title>Are fine-grained and coarse-grained dynamic information flow control always equally expressive?</title><link>https://www.cse.chalmers.se/research/group/security/event/2022/2022-01-21/</link><pubDate>Fri, 21 Jan 2022 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2022/2022-01-21/</guid><description>&lt;p>Aslan Askarov is an Associate Professor in the Department of Computer Science, Aarhus University. He received his Ph.D. in Computer Science from the Chalmers University of Technology in 2009. Before joining Aarhus University in 2014, he was a Postdoctoral Associate at Harvard University, Cambridge, MA, USA, and earlier at Cornell University, Ithaca, NY, USA. He is a recipient of the Sapere Aude Research Leader grant from the Danish National Science Research Council in 2016. His research interests lie in the areas of computer security and privacy and programming language design and implementation.&lt;/p></description></item><item><title>Building Practical Security Systems for the Post-app Smart Home</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-12-10/</link><pubDate>Fri, 10 Dec 2021 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-12-10/</guid><description>&lt;p>Adwait Nadkarni is an Assistant Professor in the Department of Computer Science, and director of the Secure Platforms Lab (SPL) at William &amp;amp; Mary. Prof. Nadkarni’s primary research domain is security and privacy, with a focus on emerging platforms, and the areas of operating systems and software security. His research is generously supported by the National Science Foundation (NSF) and the Commonwealth of Virginia’s Cyber Initiative (CCI). Prior to joining William &amp;amp; Mary, Prof. Nadkarni earned his Bachelor of Engineering (BE) in Computer Engineering from the University of Mumbai in July 2011, followed by his Ph.D. and M.S. in Computer Science from the Computer Science Department at the North Carolina State University in May 2017 and December 2012 respectively, both with Dr. William Enck. At NC State, Prof. Nadkarni was a founding member of the Wolfpack Security and Privacy Research (WSPR) Lab, and served as its Lead Graduate Student until May 2017.&lt;/p></description></item><item><title>Retrofitting Impure Languages with Static Information-Flow Control</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-12-03/</link><pubDate>Fri, 03 Dec 2021 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-12-03/</guid><description/></item><item><title>Is Privacy by Construction Possible?</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-11-19-gerardo/</link><pubDate>Fri, 19 Nov 2021 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-11-19-gerardo/</guid><description>&lt;p>Gerardo Schneider is a professor of Computer Science at the University of Gothenburg, Sweden. He had previously been at VERIMAG (Grenoble, France), Uppsala University (Sweden), Irisa/INRIA (Rennes, France), and the University of Oslo (Norway). He currently is the Head of the Formal Methods Unit at the Dept. of Computer Science and Engineering (since 2017). His research interests include formal verification (runtime verification, model checking, and verification of real-time and hybrid systems), the specification and analysis of normative documents, and privacy.&lt;/p></description></item><item><title>CoVault: Facilitating highly secure, high-stakes data analytics</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-11-03-deepak/</link><pubDate>Wed, 03 Nov 2021 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-11-03-deepak/</guid><description>&lt;p>Deepak Garg is a tenured faculty member at the Max Planck Institute
for Software Systems in Kaiserslautern and Saarbruecken, Germany. His
research focuses on the design of secure software systems,
language-based security and programming languages. Deepak has a PhD
from Carnegie Mellon University.&lt;/p>
&lt;!--
Slides can be added in a few ways:
- **Create** slides using Wowchemy's [*Slides*](https://wowchemy.com/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file
- **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file
- **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://wowchemy.com/docs/writing-markdown-latex/).
Further event details, including page elements such as image galleries, can be added to the body of this page.--></description></item><item><title>Buy the ticket, take the ride: 25 years in infosec</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-10-29-css-talk50/</link><pubDate>Fri, 29 Oct 2021 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-10-29-css-talk50/</guid><description>&lt;p>Iván Arce is Chief Technology Office (CTO) at Quarkslab, a french
information security company specialized in high value-added security
consulting services and products. Ivan is responsible for integrating
the company&amp;rsquo;s security analysis know-how into Quark Flow, Quarkslab&amp;rsquo;s
scalable security analysis platform. Prior to joining Quarkslab, Arce
created and lead &amp;ldquo;Programa STIC&amp;rdquo; (Security in ICT Program) at
Fundación Sadosky, a non-for-profit organization of the Ministry of
Science and Technology of Argentina. Before joining Fundación
Sadosky, Arce co-founded Core Security Technologies, an infosec
company from Argentina, where he worked for 16 years in multiple
roles, ranging from security consultant and software developer, to
director of security consulting services, VP of Engineering and CTO.
During his tenure at Core Security, the company grew from a team of 5
security consultants to a services and products company with over a
hundred employees that created and popularized a new market segment
(penetration testing software), pioneered industry-lead vulnerability
and exploit research &amp;amp; disclosure, and serviced thousands of customers
worldwide. Prior to founding Core Security, he worked at a computer
telephony integration startup while studying Electronic Engineering at
University of Buenos Aires, Argentina.&lt;/p>
&lt;p>Iván was a founding editorial board member of the IEEE Security &amp;amp;
Privacy magazine, co-editor of the Attack Trends department for ~10
years, and co-founder of the IEEE Center for Secure Design. He is
author of numerous articles and papers and a frequent speaker at
infosec industry and practitioner conferences.&lt;/p></description></item><item><title>Perils of Breached Passwords and How to Protect from Them</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-10-22-css-talk49/</link><pubDate>Fri, 22 Oct 2021 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-10-22-css-talk49/</guid><description>&lt;p>Rahul Chatterjee is an Assistant professor at the University of
Wisconsin–Madison. Rahul’s research focuses on improving user
authentication systems and understanding and mitigating violence
mediated by digital technologies. His work on how to safely tolerate
typos in passwords has received the Distinguished Paper award at IEEE
S&amp;amp;P (Oakland) 2016. Rahul completed his PhD from Cornell and received
his masters from UW-Madison.&lt;/p></description></item><item><title>Practical Data Access Minimization in Trigger-Action Platforms</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-10-08-css-talk48/</link><pubDate>Fri, 08 Oct 2021 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-10-08-css-talk48/</guid><description/></item><item><title>Securing Software in the Presence of Third-Party Modules</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-10-01-css-talk47/</link><pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-10-01-css-talk47/</guid><description>&lt;hr></description></item><item><title>Challenges of User-centric Privacy Enhancing Technologies</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-09-17-css-talk46/</link><pubDate>Fri, 17 Sep 2021 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-09-17-css-talk46/</guid><description>&lt;p>Simone Fischer-Hübner&amp;rsquo;s Honorary Doctorate Lecture.&lt;/p>
&lt;p>Other honorary doctors will speak before and after Simone - feel free
to attend the whole event 4pm-6pm! (If you attend in person, please do
come at 4pm.)&lt;/p>
&lt;p>Limited seats, register via &lt;a href="mailto:events@chalmers.se">events@chalmers.se&lt;/a> to attend in person.&lt;/p></description></item><item><title>Differential Privacy — A Balancing Act</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-06-18-css-talk45/</link><pubDate>Fri, 18 Jun 2021 14:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-06-18-css-talk45/</guid><description>&lt;p>More details about the thesis: &lt;a href="https://research.chalmers.se/en/publication/523824">https://research.chalmers.se/en/publication/523824&lt;/a>&lt;/p>
&lt;p>Zoom Password: 1999&lt;/p></description></item><item><title>High-Assurance Cryptography Software in the Spectre Era</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-06-11-css-talk44/</link><pubDate>Fri, 11 Jun 2021 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-06-11-css-talk44/</guid><description>&lt;p>To appear in the Proceedings of the IEEE Symposium on Security and
Privacy, 2021. &lt;a href="https://eprint.iacr.org/2020/1104">https://eprint.iacr.org/2020/1104&lt;/a>&lt;/p></description></item><item><title>A different perspective on libraries for information-flow control</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-06-04-css-talk43/</link><pubDate>Fri, 04 Jun 2021 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-06-04-css-talk43/</guid><description/></item><item><title>Fuzz Testing Automotive Systems - Process and Practice</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-05-27-css-talk42/</link><pubDate>Thu, 27 May 2021 10:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-05-27-css-talk42/</guid><description/></item><item><title>Can we enforce GDPR principles via information flow control?</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-05-07-css-talk40/</link><pubDate>Fri, 07 May 2021 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-05-07-css-talk40/</guid><description/></item><item><title>A Quantale of Information</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-04-29-css-talk39/</link><pubDate>Thu, 29 Apr 2021 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-04-29-css-talk39/</guid><description>&lt;p>Joint work with Sebastian Hunt, City, University of London. (Conditionally accepted to CSF 2021.)&lt;/p></description></item><item><title>On the Evolution of IT Security</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-04-16-css-talk38/</link><pubDate>Fri, 16 Apr 2021 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-04-16-css-talk38/</guid><description>&lt;p>David Jacoby is a senior security researcher at Kaspersky Lab. David has worked with IT security for over 25 years, and his fields of expertise include vulnerability and threat research, product and security audits, penetration tests, and security research. In his day to day job, David works on improving awareness of the current and future threats and vulnerabilities to which both consumers and large enterprises are exposed and fight cybercrime.&lt;/p>
&lt;p>In addition, David worked as the technical advisor for the continuation of the Millennium books written by David Lagercrantz. He has also been included in multiple other books such as &amp;ldquo;A Guide to Kernel Exploitation: Attacking the Core&amp;rdquo;, &amp;ldquo;Generation 500&amp;rdquo; and &amp;ldquo;Svenska Hackare&amp;rdquo;. Additional to being an advisor for book projects David is also often seen on TV in programs such as “Stoppa Tjuven” and TV4 Nyhetsmorgon.&lt;/p></description></item><item><title>SoK: Chasing Accuracy and Privacy, and Catching Both in Differentially Private Histogram Publication</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-04-09-css-talk37/</link><pubDate>Fri, 09 Apr 2021 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-04-09-css-talk37/</guid><description/></item><item><title>Towards new fuzzing frontiers: exploring the boundaries of testing</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-03-18-css-talk36/</link><pubDate>Thu, 18 Mar 2021 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-03-18-css-talk36/</guid><description>&lt;p>Mathias Payer is a security researcher and assistant professor at EPFL, leading the HexHive group. His research focuses on protecting applications in the presence of vulnerabilities, with a focus on memory corruption and type violations. He is interested in software security, system security, binary exploitation, effective mitigations, fault isolation/privilege separation, strong sanitization, and software testing (fuzzing) using a combination of binary analysis and
compiler-based techniques. Research in the HexHive group is generously supported by the ERC, SNSF, DARPA, ONR, AFOSR, or NSF, as well as several industry partners. Follow him on Twitter @gannimo. Details about his group are at &lt;a href="https://hexhive.epfl.ch">https://hexhive.epfl.ch&lt;/a>&lt;/p></description></item><item><title>Practical secure compilation using WebAssembly</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-03-12-css-talk35/</link><pubDate>Fri, 12 Mar 2021 17:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-03-12-css-talk35/</guid><description/></item><item><title>Liquid Information Flow Control</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-03-05-css-talk34/</link><pubDate>Fri, 05 Mar 2021 17:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-03-05-css-talk34/</guid><description>&lt;p>Nadia Polikarpova is an assistant professor at UC San Diego, and a member of the Programming Systems group. She received her Ph.D. in Computer Science from ETH Zurich in 2014, and then spent a couple years as a postdoctoral researcher at MIT. Nadia&amp;rsquo;s research interests are in program synthesis, program verification, and type systems. She is a 2020 Sloan Fellow, and a recipient of the 2020 NSF Career Award and the 2020 Intel Rising Stars Award.&lt;/p></description></item><item><title>w0RLd w1dE W3b - The dangers of web security inconsistencies</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-02-26-css-talk33/</link><pubDate>Fri, 26 Feb 2021 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-02-26-css-talk33/</guid><description>&lt;p>Stefano Calzavara is a tenure-track assistant professor at Università Ca' Foscari Venezia, Italy. He holds a National Scientific License (ASN) for the role of Associate Professor in Computer Science and Information Engineering from the end of 2019.&lt;/p>
&lt;p>Stefano&amp;rsquo;s research focuses on formal methods, computer security and their intersection, with a strong emphasis on web security. Stefano has published 46 papers on these topics at widely recognized international conferences and journals, including IEEE S&amp;amp;P, ACM CCS, NDSS, USENIX Security, WWW, IEEE CSF, ESOP, ACM CSUR, ACM TOPLAS and ACM TWEB. He is pleased to regularly serve in the program committees of a number of scientific events, including flagship conferences like ACM CCS, USENIX Security, WWW, IEEE EuroS&amp;amp;P and IEEE CSF.&lt;/p></description></item><item><title>Let's not make a fuzz about it</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-02-19-css-talk32/</link><pubDate>Fri, 19 Feb 2021 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-02-19-css-talk32/</guid><description/></item><item><title>HMAC and 'Secure Preferences': Revisiting Chromium-Based Browsers Security</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-02-05-css-talk31/</link><pubDate>Fri, 05 Feb 2021 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-02-05-css-talk31/</guid><description/></item><item><title>Security Assurance Cases for Road Vehicles: an Industry Perspective</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-01-29-css-talk30/</link><pubDate>Fri, 29 Jan 2021 13:15:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-01-29-css-talk30/</guid><description/></item><item><title>An Overview of Vehicular Security</title><link>https://www.cse.chalmers.se/research/group/security/event/2021/2021-01-22-css-talk29/</link><pubDate>Fri, 22 Jan 2021 13:30:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2021/2021-01-22-css-talk29/</guid><description/></item><item><title>Decentralized Action Integrity for Trigger-Action Platforms</title><link>https://www.cse.chalmers.se/research/group/security/event/2020/2020-11-20-css-talk28/</link><pubDate>Fri, 20 Nov 2020 16:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2020/2020-11-20-css-talk28/</guid><description>&lt;p>Earlence Fernandes (&lt;a href="http://www.earlence.com/">http://www.earlence.com/&lt;/a>) is an Assistant Professor in the Computer Sciences department at UW Madison. His research interests are in emerging cyber-physical systems like smart homes, buildings and vehicles. He has been awarded two best papers (at Oakland and IEEE SecDev) for his work on smart homes. He earned his PhD at the University of Michigan in 2017.&lt;/p></description></item><item><title>When Good Components Go Bad: Formally Secure Compilation Despite Dynamic Compromise</title><link>https://www.cse.chalmers.se/research/group/security/event/2019/2019-12-05-css-talk27/</link><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2019/2019-12-05-css-talk27/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Catalin Hritcu from Inria Paris, France \&lt;br>
&lt;strong>When:&lt;/strong> 14:00 - 15:00 Thursday {{ page.date | date_to_long_string }}\&lt;br>
&lt;strong>Where:&lt;/strong> Room ES52, Linsen (Maskingränd 2).\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;/p>
&lt;p>We propose a new formal criterion for evaluating secure
compartmentalization schemes for unsafe languages like C and C++,
expressing end-to-end security guarantees for software components that
may become compromised after encountering undefined behavior&amp;mdash;for
example, by accessing an array out of bounds. Our criterion is the
first to model dynamic compromise in a system of mutually distrustful
components with clearly specified privileges. It articulates how each
component should be protected from all the others&amp;mdash;in particular,
from components that have encountered undefined behavior and become
compromised.
To illustrate the model, we construct a secure compilation chain for a
small unsafe language with buffers, procedures, and components,
targeting a simple abstract machine with built-in
compartmentalization. We propose a novel proof technique and give a
machine-checked proof in Coq that this compiler satisfies our secure
compilation criterion. Finally, we show that the protection guarantees
offered by the compartmentalized abstract machine can be achieved at
the machine-code level using either software fault isolation or a
tag-based reference monitor.&lt;/p>
&lt;p>&lt;strong>Speaker Bio:&lt;/strong>\&lt;/p>
&lt;p>&lt;a href="https://prosecco.gforge.inria.fr/personal/hritcu" target="_blank" rel="noopener">Catalin Hritcu&lt;/a> is a
researcher at Inria Paris where he works on security foundations. He is
particularly interested in formal methods for security (secure compilation,
compartmentalization, memory safety, security protocols, integrity, information
flow), programming languages (program verification, proof assistants, type
systems, semantics, formal metatheory, certified tools, property-based testing),
and the design and verification of security-critical systems (reference
monitors, secure compilation chains, secure hardware). He was awarded an ERC
Starting Grant on formally secure compilation
&lt;a href="https://secure-compilation.github.io" target="_blank" rel="noopener">(https://secure-compilation.github.io)&lt;/a>,
and is also actively involved in the design of the F* verification system
&lt;a href="https://www.fstar-lang.org/" target="_blank" rel="noopener">(https://www.fstar-lang.org/)&lt;/a>, which is used for
building a formally verified HTTPS stack
&lt;a href="https://project-everest.github.io" target="_blank" rel="noopener">(https://project-everest.github.io)&lt;/a>. Catalin
received a PhD from Saarland University in Saarbrücken, a Habilitation from ENS
Paris, and was previously also a Research Associate at University of
Pennsylvania and a Visiting Researcher at Microsoft Research Redmond.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Risk Analysis of Privacy Policies</title><link>https://www.cse.chalmers.se/research/group/security/event/2019/2019-11-22-css-talk26/</link><pubDate>Fri, 22 Nov 2019 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2019/2019-11-22-css-talk26/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Raúl Pardo Jimenez from IT University of Copenhagen, Denmark \&lt;br>
&lt;strong>When:&lt;/strong> 11:00 - 12:00 Friday {{ page.date | date_to_long_string }}\&lt;br>
&lt;strong>Where:&lt;/strong> Room 8103, EDIT building.\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;/p>
&lt;p>In this talk, I present an approach to enhance informed consent
for the processing of personal data. The approach relies on a
privacy policy language used to express, compare and analyze
privacy policies. I describe a tool that automatically reports
the privacy risks associated with a given privacy policy in order
to enhance data subjects' awareness and to allow them to make
more informed choices. The risk analysis of privacy policies is
illustrated with an IoT example.&lt;/p>
&lt;p>This talk is based on work published at
DBSec19, and a paper under submission to the Journal of Computer
Security. You can find an publicly available version of the paper here
&lt;a href="https://hal.inria.fr/hal-02067924v2">https://hal.inria.fr/hal-02067924v2&lt;/a>&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>The Simplest Multi-key Linearly Homomorphic Signature Scheme</title><link>https://www.cse.chalmers.se/research/group/security/event/2019/2019-10-17-css-talk25/</link><pubDate>Thu, 17 Oct 2019 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2019/2019-10-17-css-talk25/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Elena Pagnin from Aarhus University, Denmark \&lt;br>
&lt;strong>When:&lt;/strong> 10:00 - 11:00 Thursday {{ page.date | date_to_long_string }}\&lt;br>
&lt;strong>Where:&lt;/strong> Room 8103, EDIT building.\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
We consider the problem of outsourcing computation on data authenticated by different users.
Our aim is to describe and implement the simplest possible solution to provide data integrity in cloud-based scenarios.
Concretely, our multi-key linearly homomorphic signature scheme (mklhs) allows users to upload signed data on a server,
and at any later point in time any third party can query the server to compute a linear combination of data authenticated
by different users and check the correctness of the returned result. Our construction generalizes Boneh et al.’s linearly
homomorphic signature scheme (PKC’09 [7]) to the multi-key setting and relies on basic tools of pairing-based cryptography.
Compared to existing multi-key homomorphic signature schemes, our mklhs is a conceptually simple and elegant direct construction,
which trades-off privacy for efficiency. The simplicity of our approach leads us to a very efficient construction that enjoys
significantly shorter signatures and higher performance than previous proposals. Finally, we implement mklhs using two
different pairing-friendly curves at the 128-bit security level, a Barreto-Lynn-Scott curve and a Barreto-Naehrig curve.
Our benchmarks illustrate interesting performance trade-offs between these parameters, involving the cost of exponentiation and
hashing inpairing groups.
We provide a discussion on such trade-offs that can be useful to other implementers of pairing-based protocols.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>The Rush Dilemma: Attacking and Repairing Smart Contracts on Forking Blockchains</title><link>https://www.cse.chalmers.se/research/group/security/event/2019/2019-10-16-css-talk24/</link><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2019/2019-10-16-css-talk24/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Daniele Friolo from Sapienza University of Rome, Italy \&lt;br>
&lt;strong>When:&lt;/strong> 15:00 - 16:00 Wednesday {{ page.date | date_to_long_string }}\&lt;br>
&lt;strong>Where:&lt;/strong> Room 5128, EDIT building.\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;/p>
&lt;p>We investigate the security of smart contracts within a blockchain that can fork (as Bitcoin and Ethereum). In particular, we focus on multi-party computation (MPC) protocols run on-chain with the aid of smart contracts, and observe that honest players face the following dilemma: Should I rush sending protocol&amp;rsquo;s messages based on the current view of the blockchain, or rather wait that a message is confirmed on the chain before sending the next one?&lt;/p>
&lt;p>To the best of our knowledge, the (implicit) default option used in previous work is the second one and thus known on-chain MPC protocols take long time to be executed on those blockchains with a long confirmation time (e.g., 1 hour per transaction in Bitcoin). While the first option would clearly be preferable for efficiency, we show that this is not necessarily the case for security, as there are natural examples of on-chain MPC protocols that simply become insecure in presence of rushing players.&lt;/p>
&lt;p>Our contributions are twofold:&lt;/p>
&lt;ul>
&lt;li>For the concrete case of fairly tossing multiple coins with penalties, we show that the lottery protocol of Andrychowicz et al. (S&amp;amp;P &amp;lsquo;14) becomes insecure in the presence of rushing players. In addition, we present a new protocol that instead retains security even if the players are rushing.&lt;/li>
&lt;li>We design a compiler that takes any on-chain MPC protocol and transforms it into another one (for the same task) that remains secure even in the presence of rushing players. The only (unavoidable) requirement is that honest players start to be rushing after the first round of the protocol (by all players) has been confirmed on the blockchain.&lt;/li>
&lt;/ul>
&lt;p>Our techniques are inspired by ideas on resettably secure computation (Goyal and Sahai, EUROCRYPT &amp;lsquo;09). We also provide a prototype implementation of our coin tossing protocol using Ethereum smart contracts, and instantiate our generic compiler in a concrete setting, showing that both our constructions yield considerable improvements in terms of efficiency.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>SAID: Reshaping Signal into an Identity-Based Asynchronous Messaging Protocol with Authenticated Ratcheting</title><link>https://www.cse.chalmers.se/research/group/security/event/2019/2019-04-24-css-talk23/</link><pubDate>Wed, 24 Apr 2019 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2019/2019-04-24-css-talk23/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Elena Pagnin from Aarhus University, Denmark \&lt;br>
&lt;strong>When:&lt;/strong> 10:00 - 11:00 Wednesday {{ page.date | date_to_long_string }}\&lt;br>
&lt;strong>Where:&lt;/strong> Room Analysen, EDIT building.\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
As messaging applications are becoming increasingly popular, it is of utmost importance to analyze their security and mitigate existing weaknesses. This paper focuses on one of the most acclaimed messaging applications: Signal.&lt;/p>
&lt;p>Signal is a protocol that provides end-to-end channel security, forward secrecy, and post-compromise security. These features are achieved thanks to a key-ratcheting mechanism that updates the key material at every message. Due to its high security impact, Signal’s key-ratcheting has recently been formalized, along with an analysis of its security.&lt;/p>
&lt;p>In this paper, we revisit Signal, describing some attacks against the original design and proposing SAID: Signal Authenticated and IDentity-based. As the name indicates, our protocol relies on an identity-based setup, which allows us to dispense with Signal’s centralized server. We use the identity-based long-term secrets to obtain persistent and explicit authentication, such that SAID achieves higher security guarantees than Signal.&lt;/p>
&lt;p>We prove the security of SAID not only in the Authenticated Key Exchange (AKE) model (as done by previous work), but also in the Authenticated and Confidential Channel Establishment (ACCE) model, which we adapted and redefined for SAID and asynchronous messaging protocols in general into a model we call identity-based Multistage Asynchronous Messaging (iMAM). We believe our model to be more faithful in particular to the true security of Signal, whose use of the message keys prevents them from achieving the composable guarantee claimed by previous analysis.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Trusted Execution Environments for Privacy-preserving Cloud Applications</title><link>https://www.cse.chalmers.se/research/group/security/event/2018/2018-01-26-css-talk22/</link><pubDate>Fri, 26 Jan 2018 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2018/2018-01-26-css-talk22/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Pascal Felber from the University of Neuchâtel, Switzerland \&lt;br>
&lt;strong>When:&lt;/strong> 11:15 - 12:30 Friday{{ page.date | date_to_long_string }}\&lt;br>
&lt;strong>Where:&lt;/strong> EL42, EDIT building.\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
In this talk, we will give an overview of popular trusted execution environments (TEEs), with special emphasis on Intel&amp;rsquo;s SGX, and we will describe how they can be exploited for implementing privacy-preserving operations in the Cloud that are both secure and efficient. We will discuss their main benefits and limitations, and we will present some of the recent systems that have been developed on top of them.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>CLIO: Cryptographically Secure Information Flow Control on Key-Value Stores</title><link>https://www.cse.chalmers.se/research/group/security/event/2017/2017-05-05-css-talk21/</link><pubDate>Fri, 05 May 2017 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2017/2017-05-05-css-talk21/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Pablo Buiras, PhD from Chalmers, now PostDoc at Harvard university\&lt;br>
&lt;strong>When:&lt;/strong> 10:30 - 11:30 Friday{{ page.date | date_to_long_string }}\&lt;br>
&lt;strong>Where:&lt;/strong> room EDIT 3364\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
Cryptography can in principle be used to protect users' data when stored
or transmitted, but in practice is error-prone and can potentially
result in a violation of a user&amp;rsquo;s security concerns.
Information flow control (IFC) systems, on the other hand,
can automatically enforce security policies on data with
policy languages expressive enough to capture many desired
confidentiality and integrity requirements.
In this talk I will present CLIO, an Information flow control (IFC)
system that transparently incorporates cryptography
to enforce confidentiality and integrity policies on untrusted key-value storage.
CLIO insulates developers from explicitly manipulating keys and cryptographic
primitives by leveraging the policy language of the IFC system to
automatically use the appropriate keys and correct cryptographic operations.
Our system relies on a CPA-secure cryptosystem, and we show that CLIO is secure
with a novel proof technique composing cryptographic proof techniques with standard
programming language techniques.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Historical Analyses of the Client-Side Web Security and How to tell people they have an issue</title><link>https://www.cse.chalmers.se/research/group/security/event/2017/2017-04-06-css-talk20/</link><pubDate>Thu, 06 Apr 2017 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2017/2017-04-06-css-talk20/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> room EDIT 8103\&lt;br>
&lt;strong>When:&lt;/strong> 9:30-10:30{{ page.date | date_to_long_string }}\&lt;br>
&lt;strong>Where:&lt;/strong> room EDIT 8103 \&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
In this talk, I will present two lines of research I am
currently pursuing. On the one hand, my work focusses on client-side Web
security. To better understand how the eco system evolved, we conducted
a historical study of the last 20 years of the Web using data from the
Internet Archive. Given that the Archive stores all client-side code as
well as relevant header information, this enabled us to analyze trends
over the last years, which allow us to draw conclusions on how future
security mechanisms should be implemented.&lt;/p>
&lt;p>On the other hand, while as a community we have become very good at
discovering vulnerabilities at scale (regardless of Web or network level
flaws), informing the affected parties about the issues has only been
treated as a side note in previous research. To understand how such
notifications can be conducted at scale, we conducted an experiment in
which we notified more than 44,000 vulnerable domains, using different
communication channels. Our work shows that reaching administrators is
the biggest roadblock to a successful notification. In my talk, I will
also discuss some of the technical and human challenges we face when
notifying at scale, moreover highlighting which of these areas require
further research.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Recent work on probabilistic programming languages</title><link>https://www.cse.chalmers.se/research/group/security/event/2017/2017-03-06-css-talk19/</link><pubDate>Mon, 06 Mar 2017 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2017/2017-03-06-css-talk19/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Daniel Huang \&lt;br>
&lt;strong>When:&lt;/strong> 16.00 {{ page.date | date_to_long_string }}\&lt;br>
&lt;strong>Where:&lt;/strong> 5128 (Grouproom) \&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
In this talk, we will present some of our recent work on probabilistic programming languages. In the first half of the talk, we will describe a semantics for these languages based on Type-2 computable distributions. Such an approach enables us to reason denotationally about probabilistic programs as well as in terms of sampling. In the second half, we will describe a compiler for a simple probabilistic programming language. The compiler uses a sequence of intermediate languages to gradually and successively transform a specification of a probabilistic model into a Markov Chain Monte Carlo inference algorithm for execution on the CPU or GPU.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Privacy and security threat modeling: current research directions</title><link>https://www.cse.chalmers.se/research/group/security/event/2017/2017-02-08-css-talk18/</link><pubDate>Wed, 08 Feb 2017 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2017/2017-02-08-css-talk18/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Riccardo Scandariato \&lt;br>
&lt;strong>When:&lt;/strong> 11h00 - 11h30 {{ page.date | date_to_long_string }}\&lt;br>
&lt;strong>Where:&lt;/strong> Lindholmen, Jupiter building, 4th floor, room 473\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
Threat analysis is the cornerstone of security-by-design and privacy-by-design approaches for building more secure and privacy-friendly software systems. Threat analysis provides the means to assess a design model (e.g., a software architecture) and identify potential flaws early on in the software development life-cycle. This talk will overview the issues we (empirically) found in state-of-the-practice threat analysis techniques.
Moving forward, the talk will outline our present research directions in the field of threat analysis, with particular focus on a) improving the efficiency of said techniques and b) supporting automated analysis and refactoring.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Security and Privacy on Medical Devices</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-10-26-css-talk17/</link><pubDate>Wed, 26 Oct 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-10-26-css-talk17/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Pablo Picazo\&lt;br>
&lt;strong>When:&lt;/strong> Friday, {{ page.date | date_to_long_string }}\&lt;br>
&lt;strong>Where:&lt;/strong> room 5128\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
The new generation of Implantable Medical Devices (IMDs) is a reality but the security threats mainly linked to the inclusion of wireless connectivity seem to have not received the adequate attention. The security mechanisms supported on-board of these devices must guarantee a balance between the patient safety and the security of the device &amp;ndash; that is, a trade-off between the normal operation mode and the emergency mode. Once introduced the particularities and the security risks of these devices, different security solutions will be revised in the context of identification, key generation, random number generation, etc.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>ZKBoo: Faster Zero-Knowledge for Boolean Circuits</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-08-25-css-talk6/</link><pubDate>Thu, 25 Aug 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-08-25-css-talk6/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> &lt;a href="https://link.com/" target="_blank" rel="noopener">Fname Lname&lt;/a>\&lt;br>
&lt;strong>When:&lt;/strong> Thursday, {{ page.date | date_to_long_string }}, 14:00-15:00\&lt;br>
&lt;strong>Where:&lt;/strong> Room 3364\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
In this talk we describe ZKBoo, a proposal for practically efficient
zero-knowledge arguments especially tailored for Boolean circuits and
report on a proof-of-concept implementation. As an highlight, we can
generate (resp. verify) a non-interactive proof for the SHA-1 circuit in
approximately 13ms (resp. 5ms), with a proof size of 444KB. Our
techniques are based on the “MPC-in-the-head” approach to zero-knowledge
of Ishai et al. (IKOS), which has been successfully used to achieve
significant asymptotic improvements. Our contributions include: 1) A
thorough analysis of the different variants of IKOS, which highlights
their pro and cons for practically relevant soundness parameters; 2) A
generalization and simplification of their approach, which leads to
faster Sigma-protocols (that can be made non-interactive using the
Fiat-Shamir heuristic) for statements of the form “I know x such that y
= f(x)” (where f is a circuit and y a public value); 3) A case study,
where we provide explicit protocols, implementations and benchmarking of
zero-knowledge protocols for the SHA-1 and SHA-256 circuits;&lt;/p>
&lt;p>The paper was published at USENIX Security Symposium 2016 and received
best paper award.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Enhancing the COWL W3C Standard</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-06-08-css-talk16/</link><pubDate>Wed, 08 Jun 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-06-08-css-talk16/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Niklas Andreasson\&lt;br>
&lt;strong>When:&lt;/strong> 10:00, June 8 \&lt;br>
&lt;strong>Where:&lt;/strong> room EDIT 8103\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
Web applications are often composed by resources such as JavaScript
written, and provided, by different parties. This reuse leads to questions concerning security,
and whether one can trust that third-party code will not leak users’ sensitive information.
As it stands today, these concerns are well-founded.&lt;/p>
&lt;p>With the web’s current security primitives there is a trade-off between
developer flexibility and user privacy. If developers choose to include untrusted code then
users’ privacy suffers. On the other hand, if developers abstain from reusing third-party code,
user privacy is favoured, on the cost of developer flexibility. This trade-off can
partly be attributed to the fact that the security primitives are discretionary, where untrusted
code either is granted or denied access to data. After code has been granted access to data
there is no further attempt to verify that the data is used properly.&lt;/p>
&lt;p>In 2014, Stefan et al. proposed a security mechanism which called COWL
(Confinement of Origin Web Labels). COWL is a mandatory access control
which is able to let untrusted code compute on sensitive information, while confining
it. Through this, COWL is able to address some of the shortcomings of the web’s current
security mechanisms, and in the end effectively eliminate the trade-off that exists. Since
the introduction of COWL, it has gone on to become a W3C standard.&lt;/p>
&lt;p>This thesis evaluates the COWL W3C specification by deploying it in
Mozilla Firefox. While COWL aims to mainly address information leaks caused by bugs, we
bring the specification towards addressing malicious code by highlighting two
covert channels: one due to the browser layout engine, and another due to browser
optimizations. Furthermore, we implement two case studies which shows how COWL can be used, and as
part of this, note some practical problems.Through the thesis we managed to make
contributions to the COWL W3C specification.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Selene: Voting with Transparent Verification and Coercion Mitigation</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-06-08-css-talk15/</link><pubDate>Wed, 08 Jun 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-06-08-css-talk15/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Peter Y A Ryan (University of Luxembourg)\&lt;br>
&lt;strong>When:&lt;/strong> 14:30, June 8 \&lt;br>
&lt;strong>Where:&lt;/strong> room EDIT 81033\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
In conventional cryptographic E2E verification schemes, voters are
provided with encrypted ballots that enable them to confirm that their
vote is accurately included in the tally. Technically this is very
appealing, but voters, election officials etc. need to understand some
rather subtle arguments to appreciate the integrity and ballot
secrecy guarantees provided by such mechanisms.&lt;/p>
&lt;p>A simple way to achieve a degree of verifiability and ballot privacy is
to provide each voter with a unique, private tracking number. Votes are
posted on a bulletin board in the clear along with their tracking
number. Thus voters can visit the WBB confirm that there is an entry
with their tracking number showing the correct vote. The beauty of this
approach is its simplicity and understandability. There are, however,
two drawbacks: we must ensure that trackers are unique and a coercer can
demand that the voter reveal her tracking number. It is interesting to
note that the coercer must ask for the tracker before posting. If he
asks after posting the voter has a simple strategy to fool him: just
reads off a tracker number with the coercer&amp;rsquo;s required vote from the WBB.&lt;/p>
&lt;p>In this talk, I describe a scheme that addresses both of these problems.
The main idea is to close off the coercer&amp;rsquo;s window of opportunity by
ensuring that the voters only learn their tracker numbers after votes
have been posted. Notification of the trackers must provide high
assurance but be deniable. The resulting scheme provides
receipt-freeness but also provides a more immediately understandable
form of verifiability: voters can find their vote, in the clear, in the
tally identified by their secret tracker.&lt;/p>
&lt;p>However, there is a sting in the tail: a coerced voter might light on
the coercer&amp;rsquo;s tracker, or the coercer may simply claim that the tracker
is his. I describe some elaborations of the basic scheme to counter this
problem.&lt;/p>
&lt;p>&lt;a href="http://eprint.iacr.org/2015/1105.pdf">http://eprint.iacr.org/2015/1105.pdf&lt;/a>&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Verification of differential private computationss</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-31-css-talk14/</link><pubDate>Tue, 31 May 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-31-css-talk14/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Gilles Barthe (IMDEA)\&lt;br>
&lt;strong>When:&lt;/strong> 13:30, May 31 \&lt;br>
&lt;strong>Where:&lt;/strong> room EDIT 8103\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
Differential privacy is a statistical notion of privacy which achieves
compelling trade-offs between input privacy and accuracy (of outputs).
Differential privacy is also an attractive target for verification:
despite their apparent simplicity, recently proposed algorithms have
intricate privacy and accuracy proofs. We present two program logics
for reasoning about privacy and accuracy properties of probabilistic
computations. The accuracy logic captures reasoning about the union
bound, a simple but effective tool from probablility theory, whereas
the privacy logic captures fine-grained reasoning about probabilistic
couplings, a powerful tool for studying Markov chains. We illustrate
the strengths of our program logics with novel and elegant proofs of
challenging examples from differential privacy.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title> Privacy engineering: from the building blocks to the system</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-29-css-talk11/</link><pubDate>Sun, 29 May 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-29-css-talk11/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Thibaud Antignac\&lt;br>
&lt;strong>When:&lt;/strong> 11:00 am, April 29\&lt;br>
&lt;strong>Where:&lt;/strong> EDIT 8103\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
This talk will be about privacy engineering, a field mainly concerned
with techniques, methods, and tools to systematically take into account
and address privacy issues when building a system. During this journey,
we will explore the difference between security and privacy and see why
the study of privacy in a system requires an interdisciplinary approach.
Finally, we will have a look at the current research challenges needed
to be tackled to be in a situation to deliver more privacy in
information systems.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Architectural requirements for language-level control of external timing channels</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-27-css-talk10/</link><pubDate>Fri, 27 May 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-27-css-talk10/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Aslan Askarov (Aarhus University)\&lt;br>
&lt;strong>When:&lt;/strong> 14:15, April 27\&lt;br>
&lt;strong>Where:&lt;/strong> room ED\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
A promising new approach to controlling timing channels relies on distinguishing between the direct timing dependencies that are visible at the program control flow level, and the indirect timing dependencies that typically have architectural nature. The approach allows using programming language techniques to mitigate direct dependencies, while delegating the control of the indirect dependencies to the underlying hardware. An essential element in this approach is the so-called semantic interface that stipulates a set of security and functional requirements on hardware in order for the PL-level mitigation to be sound. This talk will present the semantic interface; discuss existing practical realizations from literature, and evaluate security of this approach in a setting of active adversaries that are capable to evict caches.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Frozen Realms: draft standard support for safer JavaScript plugins</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-27-css-talk13/</link><pubDate>Fri, 27 May 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-27-css-talk13/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Mark S. Miller (Google)\&lt;br>
&lt;strong>When:&lt;/strong> 10:00, May 27 \&lt;br>
&lt;strong>Where:&lt;/strong> room EDIT 3364\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
Support ultra-fine-grain protection domains in JavaScript.
Minimizing standardization, development, explanation, and runtime costs.
Maximizing security, compatibility, simplicity, and expressiveness benefits.
See &lt;a href="https://github.com/FUDCo/proposal-frozen-realms">https://github.com/FUDCo/proposal-frozen-realms&lt;/a>&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Security of login pages on the Web: who else can know your password?</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-11-css-talk12/</link><pubDate>Wed, 11 May 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-11-css-talk12/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Steven Van Acker (Chalmers)\&lt;br>
&lt;strong>When:&lt;/strong> 14:15, May 11 \&lt;br>
&lt;strong>Where:&lt;/strong> room ED\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
Most people with an online presence these days, store large amounts of information about their lives in online web services: e-mails, pictures, medical information, &amp;hellip; To prevent unauthorised access to their personal and private information, these web services require users to authenticate and this authentication is typically done using a username and password, transmitted for verification via a login page. These login pages are critical to a user’s security. If an attacker can steal a user&amp;rsquo;s username and password, they can gain access to that user&amp;rsquo;s account easily.&lt;/p>
&lt;p>In this talk we take a look at the state of the art when it comes to security of login pages. We consider several attacker models, ranging from your typical Starbucks network attacker to sophisticated nation-state attackers.&lt;/p>
&lt;p>With these attackers in mind, we look at what the ideal login page looks like, using all security measures currently built into browsers, on top of some common sense.&lt;/p>
&lt;p>Once we know what the ideal login page looks like, we also take a look at real login pages on the Web. We analysed the login pages found on the top 100,000 most popular Internet domains and (responsibly) attacked them using simulated attacker models.&lt;/p>
&lt;p>Beware: This data is part of ongoing research and the results may shock you. You may never wish to use the Web again!&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Program behavior-based fuzzing and vulnerability discovery</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-06-css-talk9/</link><pubDate>Fri, 06 May 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-05-06-css-talk9/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Gustavo Grieco (CIFASIS - CONICET and VERIMAG)
&lt;strong>When:&lt;/strong> 11:00, May 6 in
&lt;strong>Where:&lt;/strong> room EDIT 8103
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
Mutational fuzzing is a powerful tool to detect vulnerabilities in software. It requires a initial set of inputs for the program to test. A traditional criteria to select inputs is to maximize code coverage in order to try to use all the instructions at least once. Unfortunately it is still insufficient to deal with real-world code like complex parsers in order to discover vulnerable conditions.&lt;/p>
&lt;p>In this talk we introduce a new approach based on program behaviors, in which traces are extracted and analyzed using Machine Learning to detect similarity between executions. Using this approach, we show how to perform vulnerability detection as well as preliminary results on how to improve seed selection for mutational fuzzing.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title> Two Can Keep a Secret, If One of Them Uses Haskell</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-04-15-css-talk8/</link><pubDate>Fri, 15 Apr 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-04-15-css-talk8/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Alejandro Russo
&lt;strong>When:&lt;/strong> 11:00 am on April 15
&lt;strong>Where:&lt;/strong> Room 3364\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;/p>
&lt;p>For several decades, researchers from different communities have
independently focused on protecting confidentiality of data. Two
distinct technologies have emerged for such purposes: Mandatory
Access Control (MAC) and Information-Flow Control (IFC)—the
former belonging to operating systems (OS) research, while the latter
to the programming languages community. These approaches
restrict how data gets propagated within a system in order to avoid
information leaks. In this scenario, the functional programming language
Haskell plays a unique privileged role: it is able to protect confidentiality via libraries.
This talk presents an (monadic) API which statically protects confidentiality even
in the presence of advanced features like exceptions, concurrency, and mutable data structures.&lt;/p>
&lt;p>This talk is based on the paper &amp;ldquo;Functional Pearl: Two Can Keep a Secret, If One of Them Uses Haskell&amp;rdquo; presented in ICFP 2015.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Recent Breakthroughs in Obfuscation</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-04-1-css-talk7/</link><pubDate>Fri, 01 Apr 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-04-1-css-talk7/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Elena Pagnin
&lt;strong>When:&lt;/strong> Friday April 1, 11:00
&lt;strong>Where:&lt;/strong> Room 8103
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>Abstract:
This talk is supposed to give an overview of the state of the art in the area of Homomorphic Encryption (HE) and Multi-Linear Maps (MLM). The final section of the talk will deal with the definition and application of indistinguishable Obfuscation.
More precisely, I will recall the syntax of FHE schemes and provide a trivial (extremely inefficient) construction of a FHE scheme. I will then cite the most significant papers in the area, highlight the trend and evolution of FHE schemes over the years (since Gentry’s first construction in 2009) and finally conclude with a slide that shows the timing required to perform homomorphic operations on a FHE scheme implemented by Halevi.
The main focus of the talk is on Muliti-Linear Maps (MLM). Roughly speaking, MLMs can be thought of as a FHE scheme in which there is no decryption, but it is possible to check if two (top level) cipher-texts are equal or not. This latter property is called zero testing and it is the main feature, but also weakness, of MLMs. I will present the second MLM candidate, the CLT13, which is based on relatively easy mathematical tools (congruences and Chinese Remainder Theorem), and its cryptanalysis (zeroing attack).
The talk will end with an introduction to obfuscation. &amp;gt;From an abstract point of view, one could think at obfuscation as a MLM without zero testing and in which only a pre-determined sequence of operations is allowed. In practice, an obfuscator is an algorithm that takes as input a program P and outputs another program O(P). such that O(P) and P have equal outputs on equal inputs and O(P) is an intelligible program.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Formal Security Analysis of Mobile and Web Applications</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-03-17-css-talk5/</link><pubDate>Thu, 17 Mar 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-03-17-css-talk5/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> &lt;a href="https://www.sps.cs.uni-saarland.de/maffei/" target="_blank" rel="noopener">Matteo Maffei&lt;/a>\&lt;br>
&lt;strong>When:&lt;/strong> Thursday, {{ page.date | date_to_long_string }}, 13:30-14:30\&lt;br>
&lt;strong>Where:&lt;/strong> Room 3364\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
In this talk, I will present two ongoing projects on the formal
verification of security properties for mobile and web
applications.&lt;/p>
&lt;p>In the first part, I will present HornDroid, a novel technique for the
static analysis of information flow properties in Android
applications. The core idea underlying HornDroid is to use Horn
clauses for soundly abstracting the semantics of Android applications
and to express security properties as a set of proof obligations that
are automatically discharged by SMT solving. This approach makes it
possible to fine-tune the analysis in order to achieve a high degree
of precision while still relying on off-the-shelf verification tools,
thereby automatically leveraging the recent advances in this field. As
a matter of fact, HornDroid outperforms in precision state-of-the-art
Android static analysis tools on benchmarks proposed by the community,
besides being orders of magnitude faster. Moreover, HornDroid is the
first static analysis tool for Android to come with a formal proof of
soundness: besides yielding correctness assurances, this proof allowed
us to identify some critical corner-cases that affect the soundness
guarantees provided by some of the previous static analysis tools for
Android.&lt;/p>
&lt;p>In the second part, I will present Michrome, a security enforcement
tool for web applications based on micro-policies. Micro-policies,
originally proposed to implement hardware-level security monitors,
constitute a flexible and general enforcement technique, based on
assigning security tags to system components and taking security
actions based on dynamic checks over these tags. In this work, we
present the first application of micro-policies to web security, by
proposing a core browser model supporting them and studying its
effectiveness at securing web sessions. In our view, web session
security requirements are expressed in terms of a simple, purely
declarative information flow policy, which is then automatically
translated into a micro-policy implementing it. This leads to a
browser-side enforcement mechanism which is elegant, sound and
flexible, while being accessible to web developers. We show how a
large class of attacks against web sessions can be uniformly and
effectively prevented by the adoption of this approach. Since we
carefully designed micro-policies with ease of deployment in mind, we
are also able to implement our proposal as a Google Chrome extension,
Michrome: our experiments show that Michrome can be easily configured
to enforce strong security policies without breaking the websites
functionality.&lt;/p>
&lt;p>&lt;strong>Biographical Note&lt;/strong>&lt;/p>
&lt;p>Matteo Maffei is professor at Saarland University and CISPA, where he
leads the Secure and Privacy-preserving Systems group. He received his
Ph.D. in Computer Science from the University of Venice in 2006.
Matteo’s research interests are in the area of formal methods for
security analysis, with a focus on cryptographic protocols, mobile
security, and web security, as well as privacy-enhancing technologies,
in particular zero-knowledge proofs, oblivious RAM, and differential
privacy. He was granted the Emmy Noether fellowship from the German
research foundation in 2009, he served in the programme committee of
more than 40 conferences, and he is currently the regular columnist on
security and privacy of the ACM SIGLOG newsletter.ill be summarized and I will discuss future research directions on data anonymization.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Anonymization of sparse multidimensional data</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-03-08-css-talk4/</link><pubDate>Tue, 08 Mar 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-03-08-css-talk4/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> &lt;a href="http://web.imis.athena-innovation.gr/~mter/" target="_blank" rel="noopener">Manolis Terrovitis&lt;/a>\&lt;br>
&lt;strong>When:&lt;/strong> Tuesday, {{ page.date | date_to_long_string }}, 15:00-12:00\&lt;br>
&lt;strong>Where:&lt;/strong> Room 8103\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
Data privacy is of increasing importance as most human activities leave digital traces in some information system. \&lt;br>
In this presentation I will talk about data anonymization and more specifically about protection against identity disclosure in the publication of sparse multidimensional data.
The presentation will explain the notion of km-anonymity and how it is applied to collections of high dimensional data like set-values and tree-structured data.
I will sketch the techniques that anonymize data through generalization, record splitting (disassociation) and algorithms that work on tree-structured data.
The advantages and disadvantages of each approach will be summarized and I will discuss future research directions on data anonymization.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title>Daniel Hausknecht's Licentiate presentation</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-02-29-css-talk3/</link><pubDate>Mon, 29 Feb 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-02-29-css-talk3/</guid><description>&lt;p>##Talk 1:
&lt;strong>Who:&lt;/strong> William Robertson\&lt;br>
&lt;strong>When:&lt;/strong> Monday, {{ page.date | date_to_long_string }}, 10:00-11:00\&lt;br>
&lt;strong>Where:&lt;/strong> Room 8103\&lt;br>
&lt;strong>Title:&lt;/strong> &lt;em>&lt;strong>on web malware&lt;/strong>&lt;/em> (read abstract and bio below)&lt;/p>
&lt;p>##Talk 2:
&lt;strong>Who:&lt;/strong> Daniel Hausknecht&amp;rsquo;s \&lt;br>
&lt;strong>When:&lt;/strong> Monday, {{ page.date | date_to_long_string }}, 13:15-15:00\&lt;br>
&lt;strong>Where:&lt;/strong> Room EE\&lt;br>
&lt;strong>Title:&lt;/strong> &lt;em>&lt;strong>Licentiate&amp;rsquo;s defence&lt;/strong>&lt;/em> (read abstract below)\&lt;br>
[get the slides here](url for slides)&lt;/p>
&lt;p>&lt;strong>Abstract of Robertson&amp;rsquo;s talk:&lt;/strong>
The modern Web is heavily reliant on JavaScript for implementing
client-side web applications and extending browser functionality. And
yet, despite varied efforts to isolate, tame, or analyze it, JavaScript
continues to enable new attacks against the web platform.&lt;/p>
&lt;p>In this talk, I will present recent work on bypassing browser security
controls via a novel form of code reuse, and discuss a lightweight
static analysis to detect this class of vulnerabilities. Then, I will
present ZigZag, a system for hardening JavaScript-based web applications
against client-side validation vulnerabilities that relies on invariant
detection and efficient instrumentation.&lt;/p>
&lt;p>&lt;strong>Biographical Note&lt;/strong>
William Robertson is an assistant professor of Computer Science at
Northeastern University in Boston, MA, and co-directs the NEU Systems
Security Lab. His research revolves around improving the security of
operating systems, mobile devices, and the web, making use of techniques
such as security by design, program analysis, and anomaly detection.&lt;/p>
&lt;p>&lt;strong>Abstract of Hausknecht&amp;rsquo;s talk:&lt;/strong>&lt;/p></description></item><item><title>Towards more secure and usable text passwords</title><link>https://www.cse.chalmers.se/research/group/security/event/2016/2016-01-28-css-talk2/</link><pubDate>Thu, 28 Jan 2016 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2016/2016-01-28-css-talk2/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> Prof. &lt;a href="http://www.ece.cmu.edu/~lbauer/bio.html" target="_blank" rel="noopener">Lujo Bauer&lt;/a> from Carnegie Mellon University\&lt;br>
&lt;strong>When:&lt;/strong> Thursday, {{ page.date | date_to_long_string }}, 15:00\&lt;br>
&lt;strong>Where:&lt;/strong> Room EA\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>
Many security problems arise at the interface between computer systems and their users. One set of such problems relates to authentication and text-based passwords, which despite numerous shortcomings and attacks remain the dominant authentication method in computer systems.
\&lt;br>
Is pa$$w0rd1 a good password or a bad one? For several years, we&amp;rsquo;ve been studying how to help users create passwords that are hard for attackers to crack, but are still easy for users to remember and use. A key challenge in this work was to develop and validate a methodology for collecting passwords and assessing their strength and usability. I&amp;rsquo;ll discuss our approach, and how we applied it to over 50,000 participants to study the effects of password-composition policies, password-strength meters, and detailed, step-by-step feedback and guidance during the password creation policies.&lt;/p></description></item><item><title>Establishing and Maintaining Root of Trust on Commodity Computer Systems</title><link>https://www.cse.chalmers.se/research/group/security/event/2015/2015-11-27-css-talk1/</link><pubDate>Fri, 27 Nov 2015 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/event/2015/2015-11-27-css-talk1/</guid><description>&lt;p>&lt;strong>Who:&lt;/strong> &lt;a href="http://users.ece.cmu.edu/~virgil/" target="_blank" rel="noopener">Virgil Gligor&lt;/a> CMU\&lt;br>
&lt;strong>When:&lt;/strong> Friday, {{ page.date | date_to_long_string }}, 11:00-12:00\&lt;br>
&lt;strong>Where:&lt;/strong> Room 8103\&lt;br>
&lt;strong>Title: {{ page.title }}&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>\&lt;br>
Suppose that a trustworthy program must be booted on a commodity system that may contain persistent malware. For example, a formally verified micro-kernel, micro-hypervisor, or a subsystem obtained from a trustworthy provider must be booted on a computer system that runs Windows, Linux, or Android applications. Establishing root of trust assures the user that either the system is in a malware-free state in which the trustworthy-program boot takes place or the presence of malware is discovered, with high probability. Obtaining such assurance is challenging because malware can survive in system state across repeated secure- and trusted-boot operations. These operations do not always have malware-unmediated access to device memories; e.g., memories of bring-your-own devices (e.g., keyboards, consoles, printers, routers), and sometimes even disk controllers. They certainly have no unmediated access to all non-volatile memories of interconnected components of a personal system; e.g., components of home systems, autos. To date, concrete assurance for root-of-trust establishment has not been obtained on commodity systems that scale to large configurations.
\&lt;br>
Establishing root of trust makes all persistent malware ephemeral and forces the adversary to repeat the malware-insertion attack, perhaps at some added cost. Nevertheless, some malware-controlled software can always be assumed to exist in commodity operating systems and applications. The inherent size and complexity of their operating systems and applications (aka the “giants”) render them vulnerable to successful adversary attacks. In contrast, small and simple software components with rather limited function and high-assurance layered security properties (aka the “wimps”) can be resistant to adversary attacks.
Maintaining root of trust assures a user that a commodity computer’s wimps are isolated from, and safely co-exist with, adversary-controlled giants. To survive, secure wimps must use services of, or compose with, insecure giants. This appears to be “paradoxical:” wimps can counter all adversary attacks but survive only if they use giants’ adversary-controlled services from which they have to defend themselves.
\&lt;br>
I this seminar, I will illustrate the challenges of root-of-trust establishment via “verifiable boot” operations that do not require secrets, TPMs, or adversary bounds. Then, I will present a method to define a wimp’s adversary accurately and completely using a structure found in cryptographic protocols. A consequence of such definitions is the ability to produce partial orders on adversary attacks. Finally, I will present secure wimp composition with giants, via two examples of experimental systems (i.e., on-demand isolated I/O channels and a trusted display service) designed and implemented at CMU CyLab.&lt;/p>
&lt;p>&lt;strong>Biographical Note&lt;/strong>
Virgil D. Gligor received his B.Sc., M.Sc., and Ph.D. degrees from the University of California at Berkeley. He taught at the University of Maryland between 1976 and 2007, and is currently a Professor of ECE at Carnegie Mellon University. Between 2007 and 2015 he was the co-Director of CyLab. Over the past forty years, his research interests ranged from access control mechanisms, penetration analysis, and denial-of-service protection, to cryptographic protocols and applied cryptography. Gligor was an editorial board member of several ACM and IEEE journals and the Editor in Chief of the IEEE Transactions on Dependable and Secure Computing. He received the 2006 National Information Systems Security Award jointly given by NIST and NSA, the 2011 Outstanding Innovation Award of the ACM SIG on Security Audit and Control, and the 2013 Technical Achievement Award of the IEEE Computer Society.&lt;/p>
&lt;h2 id="previous-talks">Previous Talks&lt;/h2>
&lt;p>{: .t60 }
{% include list-posts tag=&amp;lsquo;csstalk&amp;rsquo;%}&lt;/p></description></item><item><title/><link>https://www.cse.chalmers.se/research/group/security/people/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/people/</guid><description/></item><item><title>Education</title><link>https://www.cse.chalmers.se/research/group/security/projects/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.cse.chalmers.se/research/group/security/projects/</guid><description/></item></channel></rss>